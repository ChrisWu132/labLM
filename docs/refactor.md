# LLM Learning Lab - é‡æ„è®¡åˆ’

## æ¦‚è¿°

**ç›®æ ‡**: å°†ç°æœ‰çš„ VibeCoding Labï¼ˆè§‚å¯Ÿ AI ç¼–ç¨‹å¹³å°ï¼‰é‡æ„ä¸º **LLM Learning Lab**ï¼ˆé¢å‘åˆä¸­ç”Ÿçš„ Prompt Engineering æ•™å­¦å¹³å°ï¼‰

**æ—¶é—´çº¿**: 4-5 å‘¨
**é˜¶æ®µæ•°**: 3 ä¸ªä¸»è¦é˜¶æ®µ + 1 ä¸ªæµ‹è¯•ä¼˜åŒ–é˜¶æ®µ

---

## ğŸ“‹ é‡æ„æ€»è§ˆ

### æ ¸å¿ƒå˜åŒ–

| ç»´åº¦ | æ—§ç³»ç»Ÿ | æ–°ç³»ç»Ÿ | å½±å“èŒƒå›´ |
|-----|--------|--------|----------|
| **å­¦ä¹ ç›®æ ‡** | è§‚å¯Ÿ AI ç¼–ç¨‹ | å­¦ä¹  Prompt Engineering | å…¨éƒ¨å†…å®¹ |
| **æ ¸å¿ƒæŠ€æœ¯** | WebContainer + Sandpack | MDX + Prompt Editor | å‰ç«¯æ ¸å¿ƒ |
| **ç”¨æˆ·äº¤äº’** | çœ‹ AI å†™ä»£ç  | è‡ªå·±å†™ prompt çœ‹è¾“å‡º | UX æµç¨‹ |
| **æ•°æ®æ¨¡å‹** | `webcontainer_projects` | `prompt_lab_progress` | æ•°æ®åº“ |
| **ä¾èµ–é¡¹** | Monaco, xterm, WebContainer | MDX, simple textarea | package.json |

### ä¿ç•™çš„éƒ¨åˆ† âœ…

- Next.js 15 + App Router
- Supabase è®¤è¯å’Œæ•°æ®åº“
- Dashboard å¸ƒå±€å’Œå¯¼èˆª
- Coach Drawer (`askCoach()`)
- è¿›åº¦è¿½è¸ªç³»ç»Ÿ
- Rate limiting æœºåˆ¶

### ç§»é™¤çš„éƒ¨åˆ† âŒ

- `@webcontainer/api`
- `@monaco-editor/react`
- `xterm` + `xterm-addon-fit`
- `webcontainer_projects` è¡¨
- AI Function Calling é€»è¾‘

### æ–°å¢çš„éƒ¨åˆ† âœ¨

- `next-mdx-remote` (MDX æ”¯æŒ)
- PromptEditor ç»„ä»¶
- LLMOutputDisplay ç»„ä»¶
- `prompt_lab_progress` è¡¨
- æˆåŠŸæ ‡å‡†æ£€æŸ¥ç³»ç»Ÿ
- Lab 1-5 MDX å†…å®¹

---

## ğŸš€ Phase 1: åŸºç¡€è®¾æ–½è¿ç§» (Week 1)

### ç›®æ ‡
å»ºç«‹æ–°ç³»ç»Ÿçš„æŠ€æœ¯åŸºç¡€ï¼Œç§»é™¤æ—§ä¾èµ–ï¼Œå‡†å¤‡æ•°æ®å±‚ã€‚

### 1.1 Dependencies æ¸…ç†

**ç§»é™¤æ—§ä¾èµ–:**

```bash
npm uninstall @webcontainer/api @monaco-editor/react xterm xterm-addon-fit
```

**æ–°å¢ä¾èµ–:**

```bash
npm install next-mdx-remote@latest
npm install react-syntax-highlighter @types/react-syntax-highlighter
# å¯é€‰ï¼šå¦‚æœéœ€è¦ prompt è¯­æ³•é«˜äº®
```

**æ›´æ–° `package.json` è„šæœ¬:**

```json
{
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "db:migrate": "supabase migration up",
    "db:reset": "supabase db reset"
  }
}
```

### 1.2 æ•°æ®åº“è¿ç§»

**åˆ›å»ºè¿ç§»æ–‡ä»¶:** `supabase/migrations/20251016000000_llm_learning_lab_initial.sql`

```sql
-- LLM Learning Lab Initial Schema
-- Created: 2025-10-16

-- 1. prompt_lab_progress â€” å­¦ç”Ÿç»ƒä¹ æäº¤è®°å½•
CREATE TABLE prompt_lab_progress (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  lab_number SMALLINT NOT NULL CHECK (lab_number BETWEEN 1 AND 5),
  exercise_id TEXT NOT NULL,
  prompt_submitted TEXT NOT NULL,
  llm_response TEXT NOT NULL,
  success BOOLEAN DEFAULT false,
  attempts INT DEFAULT 1,
  completed_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  UNIQUE(user_id, lab_number, exercise_id)
);

CREATE INDEX idx_prompt_lab_user ON prompt_lab_progress(user_id, lab_number);
CREATE INDEX idx_prompt_lab_success ON prompt_lab_progress(user_id, success, created_at DESC);

-- 2. module_progress â€” Lab çº§è¿›åº¦è¿½è¸ª
CREATE TABLE module_progress (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  module_number SMALLINT NOT NULL CHECK (module_number BETWEEN 0 AND 5),
  completed BOOLEAN DEFAULT false,
  completed_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),
  UNIQUE(user_id, module_number)
);

CREATE INDEX idx_module_progress_user
  ON module_progress(user_id, module_number);

-- è‡ªåŠ¨æ›´æ–°æ—¶é—´æˆ³
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = now();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_module_progress_updated_at
  BEFORE UPDATE ON module_progress
  FOR EACH ROW
  EXECUTE FUNCTION update_updated_at_column();

-- 3. ai_usage_log â€” ç”¨äº rate limit ä¸åˆ†æ
CREATE TABLE ai_usage_log (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  action TEXT NOT NULL,
  metadata JSONB,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now()
);

CREATE INDEX idx_ai_usage_user_action
  ON ai_usage_log(user_id, action, created_at DESC);
CREATE INDEX idx_ai_usage_created
  ON ai_usage_log(created_at DESC);

-- 4. RLS ç­–ç•¥
ALTER TABLE prompt_lab_progress ENABLE ROW LEVEL SECURITY;
ALTER TABLE module_progress ENABLE ROW LEVEL SECURITY;
ALTER TABLE ai_usage_log ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own prompt lab progress"
  ON prompt_lab_progress FOR SELECT
  USING (auth.uid() = user_id);
CREATE POLICY "Users can insert own prompt lab progress"
  ON prompt_lab_progress FOR INSERT
  WITH CHECK (auth.uid() = user_id);
CREATE POLICY "Users can update own prompt lab progress"
  ON prompt_lab_progress FOR UPDATE
  USING (auth.uid() = user_id);

CREATE POLICY "Users can view own module progress"
  ON module_progress FOR SELECT
  USING (auth.uid() = user_id);
CREATE POLICY "Users can insert own module progress"
  ON module_progress FOR INSERT
  WITH CHECK (auth.uid() = user_id);
CREATE POLICY "Users can update own module progress"
  ON module_progress FOR UPDATE
  USING (auth.uid() = user_id);

CREATE POLICY "Users can view own ai usage log"
  ON ai_usage_log FOR SELECT
  USING (auth.uid() = user_id);
CREATE POLICY "Service role can insert ai usage log"
  ON ai_usage_log FOR INSERT
  WITH CHECK (true);
```

> â„¹ï¸ åŒç›®å½•ä¸‹çš„ `20251016000001_rollback_llm_learning_lab.sql` æä¾›äº†å®Œå…¨å›æ»šè„šæœ¬ï¼Œå¯åœ¨éœ€è¦æ—¶æ’¤é”€ä»¥ä¸Šè¡¨ç»“æ„ã€‚

**è¿è¡Œè¿ç§»:**

```bash
supabase db reset  # æœ¬åœ°å¼€å‘ç¯å¢ƒ
# æˆ–
supabase migration up  # ç”Ÿäº§ç¯å¢ƒ
```

### 1.3 é…ç½® MDX æ”¯æŒ

**æ›´æ–° `next.config.mjs`:**

```javascript
/** @type {import('next').NextConfig} */
const nextConfig = {
  eslint: {
    ignoreDuringBuilds: true
  },
  typescript: {
    ignoreBuildErrors: true
  },
  images: {
    unoptimized: true
  },
  pageExtensions: ['js', 'jsx', 'ts', 'tsx', 'md', 'mdx'],
  experimental: {
    mdxRs: false, // ä½¿ç”¨ä¼ ç»Ÿ MDX loaderï¼Œä¾¿äºè‡ªå®šä¹‰ç»„ä»¶
    serverActions: {
      bodySizeLimit: '2mb'
    }
  }
}

export default nextConfig
```

**åˆ›å»º MDX ç»„ä»¶é…ç½®:** `mdx-components.tsx`

```typescript
// mdx-components.tsx (æ ¹ç›®å½•)
import type { MDXComponents } from 'mdx/types'

/**
 * æ³¨å†Œå…¨å±€ MDX ç»„ä»¶
 *
 * åç»­ä¼šåœ¨è¿™é‡ŒæŒ‚è½½ PromptEditorã€StaticPromptDemo ç­‰è‡ªå®šä¹‰ç»„ä»¶
 */
export function useMDXComponents(components: MDXComponents): MDXComponents {
  return {
    ...components
  }
}
```

### 1.4 ç¯å¢ƒå˜é‡æ›´æ–°

**æ›´æ–° `.env.local`:**

```bash
# Supabase (ä¿æŒä¸å˜)
NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJxxx...
SUPABASE_SERVICE_ROLE_KEY=eyJyyy...

# AI Provider - ç¡®è®¤ä½¿ç”¨ GPT-4o
AI_PROVIDER=openai
OPENAI_API_KEY=sk-xxx...
AI_MODEL=gpt-4o  # æ ¹æ® PRD ç¡®å®š
AI_TIMEOUT_MS=30000
AI_MAX_TOKENS=500

# Optional
NEXT_PUBLIC_APP_URL=http://localhost:3000
```

### 1.5 TypeScript ç±»å‹å®šä¹‰

**åˆ›å»º:** `types/prompt-lab.ts`

```typescript
// types/prompt-lab.ts
export interface PromptLabProgress {
  id: string
  user_id: string
  lab_number: number
  exercise_id: string
  prompt_submitted: string
  llm_response: string
  success: boolean
  attempts: number
  completed_at: string | null
  created_at: string
}

export interface ModuleProgress {
  id: string
  user_id: string
  module_number: number
  completed: boolean
  completed_at: string | null
  created_at: string
  updated_at: string
}

export interface AIUsageLog {
  id: string
  user_id: string
  action: string
  metadata?: Record<string, any>
  created_at: string
}

export interface RunPromptRequest {
  prompt: string
  labNumber: number
  exerciseId: string
}

export interface RunPromptResult {
  success: boolean
  error?: string
  output?: string
  passed?: boolean
  feedback?: string
  latencyMs?: number
}

export interface SuccessCriteria {
  exerciseId: string
  rules: SuccessRule[]
  passingScore: number
}

export interface SuccessRule {
  type: 'containsKeywords' | 'minLength' | 'maxLength' | 'format' | 'sentiment'
  value: any
}

export interface SuccessCheckResult {
  success: boolean
  feedback: string
  passedRules?: number
  totalRules?: number
}

export interface LabMetadata {
  id: number
  title: string
  description: string
  estimatedMinutes: number
  exerciseCount: number
  path: string
}

export interface LabContent {
  id: string
  mdx: string
  metadata: {
    title: string
    description: string
    estimatedMinutes: number
  }
}

export interface PromptEditorProps {
  exerciseId: string
  mode: 'readonly' | 'editable' | 'blank'
  initialValue?: string
  placeholder?: string
  maxLength?: number
  showCharCount?: boolean
  onSubmit?: (prompt: string) => Promise<void>
}

export interface LLMOutputProps {
  mode: 'static' | 'live'
  content?: string
  loading?: boolean
  error?: string | null
  success?: boolean | null
  feedback?: string
  showTokenCount?: boolean
}

export interface RateLimitConfig {
  action: string
  limit: number
  windowMinutes: number
}

export interface UserProgressSummary {
  totalLabs: number
  completedLabs: number
  currentLab: number | null
  totalExercises: number
  completedExercises: number
  successRate: number
  totalAttempts: number
}
```

### 1.6 æµ‹è¯•è¿ç§»

**éªŒè¯æ£€æŸ¥åˆ—è¡¨:**

- [ ] `npm install` æˆåŠŸï¼Œæ— æ—§ä¾èµ–å†²çª
- [ ] `supabase migration up` æˆåŠŸæ‰§è¡Œ
- [ ] `prompt_lab_progress` è¡¨åˆ›å»ºæˆåŠŸ
- [ ] RLS ç­–ç•¥æ­£å¸¸å·¥ä½œ
- [ ] å¼€å‘æœåŠ¡å™¨ `npm run dev` å¯åŠ¨æˆåŠŸ
- [ ] ç°æœ‰åŠŸèƒ½ï¼ˆç™»å½•ã€Dashboardï¼‰ä»ç„¶æ­£å¸¸

**å®Œæˆæ ‡å¿—:** åŸºç¡€è®¾æ–½å°±ç»ªï¼Œæ—  breaking changesï¼Œæ—§åŠŸèƒ½ä»å¯è¿è¡Œã€‚

---

## ğŸ”§ Phase 2: æ ¸å¿ƒç»„ä»¶å¼€å‘ (Week 2)

### ç›®æ ‡
æ„å»ºæ–°ç³»ç»Ÿçš„æ ¸å¿ƒ UI ç»„ä»¶å’Œ Server Actionsã€‚

### 2.1 PromptEditor ç»„ä»¶

**åˆ›å»º:** `components/features/prompt-lab/PromptEditor.tsx`

```typescript
'use client'

import { useState } from 'react'
import { Loader2 } from 'lucide-react'

export interface PromptEditorProps {
  exerciseId: string
  mode: 'readonly' | 'editable' | 'blank'
  initialValue?: string
  placeholder?: string
  maxLength?: number
  showCharCount?: boolean
  onSubmit?: (prompt: string) => Promise<void>
}

export function PromptEditor({
  exerciseId,
  mode,
  initialValue = '',
  placeholder = 'åœ¨è¿™é‡Œè¾“å…¥ä½ çš„ prompt...',
  maxLength = 1000,
  showCharCount = true,
  onSubmit
}: PromptEditorProps) {
  const [prompt, setPrompt] = useState(initialValue)
  const [isSubmitting, setIsSubmitting] = useState(false)

  const handleSubmit = async () => {
    if (!prompt.trim() || !onSubmit) return

    setIsSubmitting(true)
    try {
      await onSubmit(prompt)
    } finally {
      setIsSubmitting(false)
    }
  }

  return (
    <div className="prompt-editor my-4 p-4 border rounded-lg bg-white dark:bg-gray-800">
      <textarea
        value={prompt}
        onChange={(e) => setPrompt(e.target.value)}
        placeholder={placeholder}
        maxLength={maxLength}
        disabled={mode === 'readonly' || isSubmitting}
        className="w-full min-h-[120px] p-3 border rounded-md resize-y focus:outline-none focus:ring-2 focus:ring-blue-500 disabled:bg-gray-100 dark:bg-gray-700 dark:border-gray-600 dark:text-white"
        rows={4}
      />

      <div className="mt-2 flex items-center justify-between">
        {showCharCount && (
          <div className="text-sm text-gray-500 dark:text-gray-400">
            {prompt.length} / {maxLength} å­—ç¬¦
          </div>
        )}

        {mode !== 'readonly' && (
          <button
            onClick={handleSubmit}
            disabled={isSubmitting || !prompt.trim()}
            className="px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed flex items-center gap-2 transition-colors"
          >
            {isSubmitting && <Loader2 className="w-4 h-4 animate-spin" />}
            {isSubmitting ? 'è¿è¡Œä¸­...' : 'è¿è¡Œ Prompt'}
          </button>
        )}
      </div>
    </div>
  )
}
```

### 2.2 LLMOutputDisplay ç»„ä»¶

**åˆ›å»º:** `components/features/prompt-lab/LLMOutputDisplay.tsx`

```typescript
'use client'

import { Loader2, CheckCircle2, AlertCircle } from 'lucide-react'

export interface LLMOutputProps {
  mode: 'static' | 'live'
  content?: string
  loading?: boolean
  error?: string | null
  success?: boolean | null
  feedback?: string
  showTokenCount?: boolean
}

export function LLMOutputDisplay({
  mode,
  content = '',
  loading = false,
  error = null,
  success = null,
  feedback,
  showTokenCount = false
}: LLMOutputProps) {
  return (
    <div className="llm-output my-4">
      {/* Main Output */}
      <div className="border rounded-lg p-4 bg-gray-50 dark:bg-gray-900 min-h-[120px]">
        {loading && (
          <div className="flex items-center gap-2 text-gray-600 dark:text-gray-400">
            <Loader2 className="w-5 h-5 animate-spin" />
            <span>AI æ­£åœ¨æ€è€ƒ...</span>
          </div>
        )}

        {error && (
          <div className="flex items-center gap-2 text-red-600 dark:text-red-400">
            <AlertCircle className="w-5 h-5" />
            <span>âŒ å‡ºé”™äº†: {error}</span>
          </div>
        )}

        {content && !loading && !error && (
          <div className="whitespace-pre-wrap text-gray-800 dark:text-gray-200">
            {content}
          </div>
        )}

        {!content && !loading && !error && (
          <div className="text-gray-400 dark:text-gray-500 italic">
            è¿è¡Œ prompt åï¼ŒAI çš„è¾“å‡ºä¼šæ˜¾ç¤ºåœ¨è¿™é‡Œ
          </div>
        )}
      </div>

      {/* Success Feedback */}
      {success !== null && (
        <div
          className={`mt-3 p-3 rounded-lg flex items-start gap-2 ${
            success
              ? 'bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200'
              : 'bg-yellow-100 text-yellow-800 dark:bg-yellow-900 dark:text-yellow-200'
          }`}
        >
          {success ? (
            <>
              <CheckCircle2 className="w-5 h-5 flex-shrink-0 mt-0.5" />
              <div>
                <strong>å¤ªæ£’äº†!</strong> ä½ çš„ prompt è¾¾åˆ°äº†ç›®æ ‡!
              </div>
            </>
          ) : (
            <>
              <AlertCircle className="w-5 h-5 flex-shrink-0 mt-0.5" />
              <div>
                <strong>å†è¯•è¯•:</strong> {feedback || 'è¾“å‡ºè¿˜ä¸å¤ªç¬¦åˆè¦æ±‚,å°è¯•è°ƒæ•´ä½ çš„ prompt'}
              </div>
            </>
          )}
        </div>
      )}

      {/* Token Count (Optional) */}
      {showTokenCount && content && (
        <div className="text-xs text-gray-500 dark:text-gray-400 mt-2">
          çº¦ {Math.ceil(content.length / 4)} tokens
        </div>
      )}
    </div>
  )
}
```

### 2.3 Server Action: runPrompt()

**åˆ›å»º:** `lib/actions/prompt-lab.ts`

```typescript
'use server'

import { createServerSupabaseClient } from '@/lib/supabase-server'
import { checkRateLimit, logAIUsage } from '@/lib/rate-limit'
import { checkExerciseSuccess } from '@/lib/prompt-lab/success-checker'
import OpenAI from 'openai'
import type { RunPromptRequest, RunPromptResult } from '@/types/prompt-lab'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

export async function runPrompt(
  request: RunPromptRequest
): Promise<RunPromptResult> {
  const supabase = await createServerSupabaseClient()

  // 1. Get current user
  const {
    data: { user },
    error: authError
  } = await supabase.auth.getUser()

  if (authError || !user) {
    return { success: false, error: 'è¯·å…ˆç™»å½•' }
  }

  // 2. Validate input
  if (!request.prompt || request.prompt.trim().length < 10) {
    return { success: false, error: 'Prompt å¤ªçŸ­,è‡³å°‘ 10 ä¸ªå­—ç¬¦' }
  }

  if (request.prompt.length > 1000) {
    return { success: false, error: 'Prompt å¤ªé•¿,æœ€å¤š 1000 ä¸ªå­—ç¬¦' }
  }

  // 3. Rate limit check
  const allowed = await checkRateLimit(user.id, 'prompt_lab', 30, 60)
  if (!allowed) {
    return {
      success: false,
      error: 'æ“ä½œå¤ªé¢‘ç¹,è¯·ç¨åå†è¯• (æ¯å°æ—¶æœ€å¤š 30 æ¬¡)'
    }
  }

  // 4. Call GPT-4o
  const startTime = Date.now()
  let llmResponse: string

  try {
    const completion = await openai.chat.completions.create({
      model: process.env.AI_MODEL || 'gpt-4o',
      messages: [{ role: 'user', content: request.prompt }],
      max_tokens: parseInt(process.env.AI_MAX_TOKENS || '500'),
      temperature: 0.7
    })

    llmResponse = completion.choices[0].message.content || ''
  } catch (error: any) {
    console.error('[runPrompt] OpenAI API error:', error)
    return {
      success: false,
      error: 'AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨,è¯·ç¨åå†è¯•'
    }
  }

  const latencyMs = Date.now() - startTime

  // 5. Check success criteria
  const successCheck = await checkExerciseSuccess(
    request.exerciseId,
    llmResponse
  )

  // 6. Get existing attempts count
  const { data: existing } = await supabase
    .from('prompt_lab_progress')
    .select('attempts')
    .eq('user_id', user.id)
    .eq('lab_number', request.labNumber)
    .eq('exercise_id', request.exerciseId)
    .single()

  const newAttempts = (existing?.attempts || 0) + 1

  // 7. Persist submission
  const { error: upsertError } = await supabase
    .from('prompt_lab_progress')
    .upsert({
      user_id: user.id,
      lab_number: request.labNumber,
      exercise_id: request.exerciseId,
      prompt_submitted: request.prompt,
      llm_response: llmResponse,
      success: successCheck.success,
      attempts: newAttempts,
      completed_at: successCheck.success ? new Date().toISOString() : null
    })

  if (upsertError) {
    console.error('[runPrompt] Database error:', upsertError)
  }

  // 8. Log usage for rate limiting analytics
  await logAIUsage(user.id, 'prompt_lab', {
    lab_number: request.labNumber,
    exercise_id: request.exerciseId,
    success: successCheck.success,
    latency_ms: latencyMs
  })

  return {
    success: true,
    output: llmResponse,
    passed: successCheck.success,
    feedback: successCheck.feedback,
    latencyMs
  }
}
```

### 2.4 Success Criteria Checker

**åˆ›å»º:** `lib/prompt-lab/success-checker.ts`

```typescript
import type { SuccessCriteria, SuccessRule } from '@/types/prompt-lab'

/**
 * ç»ƒä¹ æˆåŠŸæ ‡å‡†é…ç½®
 */
const exerciseCriteria: Record<string, SuccessCriteria> = {
  // Lab 1
  'lab1-ex1': {
    exerciseId: 'lab1-ex1',
    rules: [
      { type: 'containsKeywords', value: ['ä¹ æ€§', 'è¡Œä¸º', 'ç‰¹ç‚¹', 'å–œæ¬¢'] },
      { type: 'minLength', value: 50 }
    ],
    passingScore: 2
  },
  'lab1-ex2': {
    exerciseId: 'lab1-ex2',
    rules: [
      { type: 'containsKeywords', value: ['æ•…äº‹', 'å†’é™©'] },
      { type: 'minLength', value: 100 }
    ],
    passingScore: 2
  },

  // Lab 2
  'lab2-ex1': {
    exerciseId: 'lab2-ex1',
    rules: [
      { type: 'containsKeywords', value: ['åˆå­¦è€…', 'ç¼–ç¨‹', 'ä»‹ç»', 'å­¦ä¹ '] },
      { type: 'minLength', value: 80 }
    ],
    passingScore: 2
  },
  'lab2-ex2': {
    exerciseId: 'lab2-ex2',
    rules: [
      { type: 'containsKeywords', value: ['1.', '2.', '3.'] },
      { type: 'minLength', value: 60 }
    ],
    passingScore: 2
  },
  'lab2-ex3': {
    exerciseId: 'lab2-ex3',
    rules: [
      { type: 'containsKeywords', value: ['title', 'author', 'year', 'genre'] },
      { type: 'containsKeywords', value: ['{', '}'] },
      { type: 'minLength', value: 30 }
    ],
    passingScore: 3
  }
  // Phase 3+ å°†ç»§ç»­è¡¥å…… lab3-5 çš„è§„åˆ™
}

export async function checkExerciseSuccess(
  exerciseId: string,
  llmOutput: string
): Promise<{ success: boolean; feedback: string }> {
  const criteria = exerciseCriteria[exerciseId]

  // No criteria = always pass (used for demo exercises)
  if (!criteria) {
    return { success: true, feedback: '' }
  }

  let passedRules = 0
  const failedRules: string[] = []

  for (const rule of criteria.rules) {
    const passed = checkRule(rule, llmOutput)
    if (passed) {
      passedRules++
    } else {
      failedRules.push(getRuleFeedback(rule))
    }
  }

  const success = passedRules >= criteria.passingScore

  let feedback = ''
  if (!success) {
    feedback = failedRules[0] || 'è¾“å‡ºè¿˜ä¸å¤ªç¬¦åˆè¦æ±‚ã€‚æç¤º: è¯•ç€è®© AI æ›´èšç„¦åœ¨å…·ä½“æ–¹é¢ã€‚'
  }

  return { success, feedback }
}

function checkRule(rule: SuccessRule, output: string): boolean {
  switch (rule.type) {
    case 'containsKeywords':
      const keywords = rule.value as string[]
      return keywords.some((kw) => output.includes(kw))

    case 'minLength':
      return output.length >= (rule.value as number)

    case 'maxLength':
      return output.length <= (rule.value as number)

    case 'format':
      // TODO: implement format checking (e.g., JSON, markdown)
      return true

    case 'sentiment':
      // TODO: implement sentiment analysis (åæœŸå¯ç”¨ LLM åˆ¤æ–­)
      return true

    default:
      return false
  }
}

function getRuleFeedback(rule: SuccessRule): string {
  switch (rule.type) {
    case 'containsKeywords':
      return `è¾“å‡ºä¸­ç¼ºå°‘å…³é”®è¯ã€‚è¯•ç€åœ¨ prompt ä¸­è¦æ±‚åŒ…å«: ${(rule.value as string[]).join('ã€')}`

    case 'minLength':
      return `è¾“å‡ºå¤ªçŸ­äº†ã€‚è¯•ç€è®© AI æä¾›æ›´è¯¦ç»†çš„å›ç­”ã€‚`

    case 'maxLength':
      return `è¾“å‡ºå¤ªé•¿äº†ã€‚è¯•ç€è®© AI æ›´ç®€æ´ã€‚`

    default:
      return 'è¾“å‡ºä¸ç¬¦åˆè¦æ±‚ã€‚'
  }
}
```

### 2.5 Rate Limit Helper (å¤ç”¨)

**ç¡®è®¤å­˜åœ¨:** `lib/rate-limit.ts`

å¦‚ä¸å­˜åœ¨,åˆ›å»º:

```typescript
import { createClient } from '@supabase/supabase-js'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!

export async function checkRateLimit(
  userId: string,
  action: string,
  limit: number,
  windowMinutes: number
): Promise<boolean> {
  const supabase = createClient(supabaseUrl, supabaseServiceKey)
  const windowStart = new Date(Date.now() - windowMinutes * 60 * 1000)

  const { count, error } = await supabase
    .from('ai_usage_log')
    .select('*', { count: 'exact', head: true })
    .eq('user_id', userId)
    .eq('action', action)
    .gte('created_at', windowStart.toISOString())

  if (error) {
    console.error('[checkRateLimit] Error:', error)
    return true // fail open
  }

  return (count || 0) < limit
}

export async function logAIUsage(
  userId: string,
  action: string,
  metadata?: Record<string, any>
) {
  const supabase = createClient(supabaseUrl, supabaseServiceKey)

  const { error } = await supabase.from('ai_usage_log').insert({
    user_id: userId,
    action,
    metadata
  })

  if (error) {
    console.error('[logAIUsage] Error:', error)
  }
}
```

### 2.6 æµ‹è¯•æ ¸å¿ƒç»„ä»¶

**åˆ›å»ºæµ‹è¯•é¡µé¢:** `app/dashboard/test-prompt/page.tsx`

```typescript
'use client'

import { useState } from 'react'
import { PromptEditor } from '@/components/features/prompt-lab/PromptEditor'
import { LLMOutputDisplay } from '@/components/features/prompt-lab/LLMOutputDisplay'
import { runPrompt } from '@/lib/actions/prompt-lab'

export default function TestPromptPage() {
  const [output, setOutput] = useState('')
  const [loading, setLoading] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [success, setSuccess] = useState<boolean | null>(null)
  const [feedback, setFeedback] = useState('')
  const [latency, setLatency] = useState<number | null>(null)

  const handleSubmit = async (prompt: string) => {
    setLoading(true)
    setSuccess(null)
    setError(null)
    setOutput('')

    const result = await runPrompt({
      prompt,
      labNumber: 1,
      exerciseId: 'lab1-ex1'
    })

    if (result.success && result.output) {
      setOutput(result.output)
      setSuccess(result.passed || false)
      setFeedback(result.feedback || '')
      setLatency(result.latencyMs || null)
      setError(null)
    }

    if (!result.success) {
      setError(result.error || 'Unknown error')
      setSuccess(null)
    }

    setLoading(false)
  }

  return (
    <div className="container mx-auto p-8 max-w-3xl">
      <h1 className="text-3xl font-bold mb-2">Prompt Lab ç»„ä»¶æµ‹è¯•</h1>
      <p className="text-gray-600 dark:text-gray-400 mb-6">
        æµ‹è¯• PromptEditor, LLMOutputDisplay, å’Œ runPrompt server action
      </p>

      <div className="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6">
        <h2 className="text-xl font-semibold mb-4">ç»ƒä¹ : è®© AI ä»‹ç»çŒ«çš„ä¹ æ€§</h2>
        <p className="text-sm text-gray-600 dark:text-gray-400 mb-4">
          å°è¯•å†™ä¸€ä¸ª promptï¼Œè®© AI ä¸“æ³¨äºä»‹ç»çŒ«çš„ä¹ æ€§ï¼ˆè€Œä¸æ˜¯æ³›æ³›è€Œè°ˆï¼‰
        </p>

        <PromptEditor
          exerciseId="lab1-ex1"
          mode="editable"
          initialValue="å‘Šè¯‰æˆ‘å…³äºçŒ«çš„ä¹ æ€§"
          onSubmit={handleSubmit}
        />

        <LLMOutputDisplay
          mode="live"
          content={output}
          loading={loading}
          error={error}
          success={success}
          feedback={feedback}
          showTokenCount
        />

        {latency !== null && (
          <div className="mt-2 text-xs text-gray-500 dark:text-gray-400">
            å“åº”æ—¶é—´: {latency}ms
          </div>
        )}
      </div>

      <div className="mt-8 p-4 bg-blue-50 dark:bg-blue-900 rounded-lg">
        <h3 className="font-semibold mb-2">âœ… Phase 2 ç»„ä»¶éªŒè¯</h3>
        <ul className="text-sm space-y-1">
          <li>âœ“ PromptEditor æ¸²æŸ“æ­£å¸¸</li>
          <li>âœ“ LLMOutputDisplay æ˜¾ç¤ºæ­£å¸¸</li>
          <li>âœ“ runPrompt server action é›†æˆ</li>
          <li>âœ“ Success checker è§„åˆ™ç”Ÿæ•ˆ</li>
          <li>âœ“ Rate limiting (30/hour)</li>
          <li>âœ“ æ•°æ®æŒä¹…åŒ–åˆ° prompt_lab_progress</li>
        </ul>
      </div>

      <div className="mt-4 p-4 bg-yellow-50 dark:bg-yellow-900 rounded-lg">
        <h3 className="font-semibold mb-2">âš ï¸ æµ‹è¯•å‰ç¡®è®¤</h3>
        <ul className="text-sm space-y-1">
          <li>â€¢ å·²å¡«å…¥ OPENAI_API_KEY åˆ° .env</li>
          <li>â€¢ å·²ç™»å½•ç”¨æˆ·è´¦æˆ·</li>
          <li>â€¢ Supabase æ•°æ®åº“å·²è¿è¡Œ</li>
        </ul>
      </div>
    </div>
  )
}
```

**éªŒè¯æ£€æŸ¥åˆ—è¡¨:**

- [ ] PromptEditor æ¸²æŸ“æ­£å¸¸
- [ ] ç‚¹å‡»"è¿è¡Œ"è°ƒç”¨ server action
- [ ] LLM API è¿”å›è¾“å‡º
- [ ] æˆåŠŸæ£€æŸ¥é€»è¾‘æ­£å¸¸å·¥ä½œ
- [ ] æ•°æ®ä¿å­˜åˆ° `prompt_lab_progress` è¡¨
- [ ] Rate limiting æ­£å¸¸å·¥ä½œ

**å®Œæˆæ ‡å¿—:** æ ¸å¿ƒç»„ä»¶å®Œæ•´å¯ç”¨,èƒ½è¿è¡Œå®Œæ•´çš„ prompt â†’ output â†’ check æµç¨‹ã€‚

---

## ğŸ“ Phase 3: Lab å†…å®¹é›†æˆ (Week 3)

### ç›®æ ‡
åˆ›å»º MDX Lab å†…å®¹,é›†æˆç»„ä»¶,å®ç°å®Œæ•´çš„å­¦ä¹ ä½“éªŒã€‚

### 3.1 åˆ›å»º Lab è·¯ç”±ç»“æ„

**æ–‡ä»¶ç»“æ„:**

```
app/dashboard/vibecoding/
â”œâ”€â”€ page.tsx                    # Lab åˆ—è¡¨é¡µ (å¤ç”¨ç°æœ‰,æ”¹æ•°æ®æº)
â””â”€â”€ labs/
    â”œâ”€â”€ [labId]/
    â”‚   â””â”€â”€ page.tsx            # åŠ¨æ€ Lab å†…å®¹é¡µ
    â””â”€â”€ _components/
        â””â”€â”€ LabWrapper.tsx      # Lab é¡µé¢åŒ…è£…å™¨
```

**åˆ›å»º:** `app/dashboard/vibecoding/labs/[labId]/page.tsx`

```typescript
import { MDXRemote } from 'next-mdx-remote/rsc'
import { getLabContent, getAllLabs } from '@/lib/lab-content'
import { notFound } from 'next/navigation'
import {
  InteractivePromptEditor,
  StaticPromptDemo
} from './_components/LabWrapper'

const components = {
  PromptEditor: InteractivePromptEditor,
  StaticPromptDemo
}

export default async function LabPage({
  params
}: {
  params: { labId: string }
}) {
  const { labId } = params
  const labContent = await getLabContent(labId)

  if (!labContent) {
    notFound()
  }

  return (
    <div className="container mx-auto px-4 py-8 max-w-4xl">
      <MDXRemote source={labContent.mdx} components={components} />
    </div>
  )
}

export async function generateStaticParams() {
  const labs = await getAllLabs()
  return labs.map((labId) => ({ labId }))
}
```

### 3.2 MDX å°è£…ç»„ä»¶

**åˆ›å»º:** `app/dashboard/vibecoding/labs/[labId]/_components/LabWrapper.tsx`

```typescript
'use client'

import { useState } from 'react'
import { PromptEditor } from '@/components/features/prompt-lab/PromptEditor'
import { LLMOutputDisplay } from '@/components/features/prompt-lab/LLMOutputDisplay'
import type { PromptEditorProps, LLMOutputProps } from '@/types/prompt-lab'
import { runPrompt } from '@/lib/actions/prompt-lab'

export function InteractivePromptEditor(props: PromptEditorProps) {
  const [output, setOutput] = useState('')
  const [loading, setLoading] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [success, setSuccess] = useState<boolean | null>(null)
  const [feedback, setFeedback] = useState('')

  const handleSubmit = async (prompt: string) => {
    setLoading(true)
    setSuccess(null)
    setError(null)

    const labNumber = parseInt(props.exerciseId.match(/lab(\d+)/)?.[1] || '1')

    const result = await runPrompt({
      prompt,
      labNumber,
      exerciseId: props.exerciseId
    })

    if (result.success && result.output) {
      setOutput(result.output)
      setSuccess(result.passed || false)
      setFeedback(result.feedback || '')
      setError(null)
    } else {
      setError(result.error || 'Unknown error')
      setSuccess(null)
    }

    setLoading(false)
  }

  return (
    <>
      <PromptEditor {...props} onSubmit={handleSubmit} />
      <LLMOutputDisplay
        mode="live"
        content={output}
        loading={loading}
        error={error}
        success={success}
        feedback={feedback}
      />
    </>
  )
}

export function StaticPromptDemo(
  props: PromptEditorProps & { demoOutput: string }
) {
  return (
    <>
      <PromptEditor {...props} mode="readonly" />
      <LLMOutputDisplay mode="static" content={props.demoOutput} />
    </>
  )
}
```

### 3.3 Lab Content Loader

**åˆ›å»º:** `lib/lab-content.ts`

```typescript
import fs from 'fs/promises'
import path from 'path'

export interface LabContent {
  id: string
  mdx: string
  metadata: {
    title: string
    description: string
    estimatedMinutes: number
  }
}

export async function getLabContent(labId: string): Promise<LabContent | null> {
  const labsDir = path.join(process.cwd(), 'content', 'labs')
  const filePath = path.join(labsDir, `${labId}.mdx`)

  try {
    const source = await fs.readFile(filePath, 'utf8')

    const titleMatch = source.match(/^# (.+)$/m)
    const title = titleMatch ? titleMatch[1] : labId

    const descMatch = source.match(/## ğŸ“– å­¦ä¹ ç›®æ ‡\n\n(.+?)\n/)
    const description = descMatch ? descMatch[1] : ''

    return {
      id: labId,
      mdx: source,
      metadata: {
        title,
        description,
        estimatedMinutes: 15
      }
    }
  } catch (error) {
    console.error(`Failed to load lab content: ${labId}`, error)
    return null
  }
}

export async function getAllLabs(): Promise<string[]> {
  const labsDir = path.join(process.cwd(), 'content', 'labs')

  try {
    const files = await fs.readdir(labsDir)
    return files
      .filter((file) => file.endsWith('.mdx'))
      .map((file) => file.replace('.mdx', ''))
      .sort()
  } catch (error) {
    console.error('Failed to list labs:', error)
    return []
  }
}
```

### 3.4 åˆ›å»º Lab 1-2 MDX å†…å®¹

**åˆ›å»ºç›®å½•:**

```bash
mkdir -p content/labs
```

**åˆ›å»º:** `content/labs/lab1.mdx`

```mdx
# Lab 1: ä»€ä¹ˆæ˜¯ Prompt

## ğŸ“– å­¦ä¹ ç›®æ ‡

- ç†è§£ä»€ä¹ˆæ˜¯ prompt
- å­¦ä¼šå†™åŸºæœ¬çš„æŒ‡ä»¤
- äº†è§£ LLM å¦‚ä½•ç†è§£è¾“å…¥

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

**Prompt** å°±æ˜¯ä½ å¯¹ AI è¯´çš„è¯ã€‚

å°±åƒä½ é—®æœ‹å‹é—®é¢˜ä¸€æ ·ï¼Œä½ å¯¹ AI è¯´ä»€ä¹ˆï¼Œå®ƒå°±ä¼šæ ¹æ®ä½ è¯´çš„è¯æ¥å›ç­”ã€‚

**ç¤ºä¾‹:**

<StaticPromptDemo
  exerciseId="lab1-demo"
  initialValue="å‘Šè¯‰æˆ‘å…³äºçŒ«çš„äº‹æƒ…"
  demoOutput="çŒ«æ˜¯ä¸€ç§å¯çˆ±çš„å®¶å…»åŠ¨ç‰©ã€‚å®ƒä»¬é€šå¸¸æœ‰æŸ”è½¯çš„æ¯›å‘ï¼Œæ•æ·çš„èº«æ‰‹ï¼Œå–œæ¬¢æ™’å¤ªé˜³å’Œç©è€ã€‚çŒ«æœ‰å¾ˆå¼ºçš„ç‹¬ç«‹æ€§ï¼Œä½†ä¹Ÿå–œæ¬¢å’Œä¸»äººäº’åŠ¨..."
/>

çœ‹åˆ°äº†å—ï¼Ÿæˆ‘ä»¬ç»™ AI ä¸€ä¸ªç®€å•çš„æŒ‡ä»¤ï¼Œå®ƒå°±ç»™å‡ºäº†å…³äºçŒ«çš„ä»‹ç»ã€‚

ä½†æ˜¯ï¼Œè¿™ä¸ªå›ç­”æœ‰ç‚¹å¤ªå®½æ³›äº†ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦æ›´å…·ä½“çš„ä¿¡æ¯å‘¢ï¼Ÿ

## âœï¸ åŠ¨æ‰‹ç»ƒä¹ 

### ç»ƒä¹  1: è®©å›ç­”æ›´å…·ä½“

**ä»»åŠ¡**: ä¿®æ”¹ä¸‹é¢çš„ promptï¼Œè®© AI çš„å›ç­”æ›´å…·ä½“ï¼Œæ¯”å¦‚åªä»‹ç»**çŒ«çš„ä¹ æ€§**ã€‚

<PromptEditor
  exerciseId="lab1-ex1"
  mode="editable"
  initialValue="å‘Šè¯‰æˆ‘å…³äºçŒ«çš„äº‹æƒ…"
/>

**ç›®æ ‡**: è¾“å‡ºåº”è¯¥ä¸“æ³¨äºçŒ«çš„ä¹ æ€§ï¼Œè€Œä¸æ˜¯æ³›æ³›è€Œè°ˆã€‚

**æç¤º**:
- è¯•ç€åœ¨ prompt ä¸­æ˜ç¡®è¯´æ˜ä½ æƒ³äº†è§£"çŒ«çš„ä¹ æ€§"
- ä½ å¯ä»¥è¯´"è¯·ä»‹ç»çŒ«çš„ä¹ æ€§"æˆ–"çŒ«æœ‰ä»€ä¹ˆè¡Œä¸ºç‰¹ç‚¹"

### ç»ƒä¹  2: è®© AI è®²æ•…äº‹

**ä»»åŠ¡**: ä»é›¶å¼€å§‹å†™ä¸€ä¸ª promptï¼Œè®© AI å†™ä¸€ä¸ªå…³äºçŒ«å†’é™©çš„å°æ•…äº‹ã€‚

<PromptEditor
  exerciseId="lab1-ex2"
  mode="blank"
  placeholder="åœ¨è¿™é‡Œå†™ä½ çš„ prompt..."
/>

**æˆåŠŸæ ‡å‡†**:
- âœ… è¾“å‡ºåŒ…å«"æ•…äº‹"å’Œ"å†’é™©"ç›¸å…³å†…å®¹
- âœ… è‡³å°‘ 100 ä¸ªå­—

**æç¤º**: è¯•ç€è¯´"å†™ä¸€ä¸ªå…³äº...çš„æ•…äº‹"

## ğŸ“ æ€»ç»“

æ­å–œä½ å®Œæˆ Lab 1ï¼ä½ å­¦ä¼šäº†ï¼š

- âœ… Prompt è¶Šå…·ä½“ï¼ŒAI çš„å›ç­”è¶Šå‡†ç¡®
- âœ… æ˜ç¡®è¯´æ˜ä½ æƒ³è¦ä»€ä¹ˆå†…å®¹
- âœ… ä¸åŒçš„ prompt ä¼šå¾—åˆ°ä¸åŒçš„è¾“å‡º

**ä¸‹ä¸€æ­¥**: [Lab 2 - å­¦ä¹ å¦‚ä½•ç»™æ¸…æ™°çš„æŒ‡ä»¤ï¼Œé¿å…æ­§ä¹‰ï¼](/dashboard/vibecoding/labs/lab2)
```

**åˆ›å»º:** `content/labs/lab2.mdx`

```mdx
# Lab 2: å¦‚ä½•ç»™æ¸…æ™°æŒ‡ä»¤

## ğŸ“– å­¦ä¹ ç›®æ ‡

- ç†è§£æ¸…æ™°è¡¨è¾¾çš„é‡è¦æ€§
- å­¦ä¼šé¿å…æ¨¡ç³Šçš„ prompt
- æŒæ¡æ·»åŠ çº¦æŸæ¡ä»¶çš„æŠ€å·§

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

**æ¸…æ™° > æ¨¡ç³Š**

AI ä¸ä¼šè¯»å¿ƒæœ¯ã€‚å¦‚æœä½ çš„ prompt æ¨¡ç³Šä¸æ¸…ï¼ŒAI åªèƒ½çŒœä½ æƒ³è¦ä»€ä¹ˆã€‚

### å¯¹æ¯”ç¤ºä¾‹

#### âŒ æ¨¡ç³Šçš„ prompt

<StaticPromptDemo
  exerciseId="lab2-demo-bad"
  initialValue="å†™ç‚¹ä¸œè¥¿"
  demoOutput="è¿™æ˜¯ä¸€äº›æ–‡å­—ã€‚æˆ‘ä¸å¤ªç¡®å®šä½ æƒ³è¦ä»€ä¹ˆå†…å®¹ï¼Œæ‰€ä»¥æˆ‘å†™äº†ä¸€äº›é€šç”¨çš„ä¸œè¥¿..."
/>

---

#### âœ… æ¸…æ™°çš„ prompt

<StaticPromptDemo
  exerciseId="lab2-demo-good"
  initialValue="å†™ä¸€æ®µ 50 å­—å·¦å³çš„æ–‡å­—ï¼Œä»‹ç»ä¸ºä»€ä¹ˆè¿åŠ¨å¯¹å¥åº·æœ‰ç›Šã€‚ä½¿ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€ã€‚"
  demoOutput="è¿åŠ¨å¯ä»¥è®©èº«ä½“æ›´å¼ºå£®ï¼Œå¿ƒè„æ›´å¥åº·ã€‚ç»å¸¸è¿åŠ¨çš„äººä¸å®¹æ˜“ç”Ÿç—…ï¼Œç²¾ç¥ä¹Ÿä¼šæ›´å¥½ã€‚æ¯å¤©è¿åŠ¨ 30 åˆ†é’Ÿï¼Œæ¯”å¦‚è·‘æ­¥ã€æ¸¸æ³³æˆ–æ‰“çƒï¼Œéƒ½èƒ½è®©ä½ å˜å¾—æ›´å¥åº·ã€æ›´å¿«ä¹ã€‚"
/>

çœ‹åˆ°åŒºåˆ«äº†å—ï¼Ÿæ¸…æ™°çš„ prompt åŒ…å«ï¼š
- âœ… æ˜ç¡®çš„ä»»åŠ¡ï¼ˆ"ä»‹ç»ä¸ºä»€ä¹ˆ..."ï¼‰
- âœ… å…·ä½“çš„è¦æ±‚ï¼ˆ"50 å­—å·¦å³"ï¼‰
- âœ… é£æ ¼æŒ‡å¯¼ï¼ˆ"ç®€å•æ˜“æ‡‚"ï¼‰

## âœï¸ åŠ¨æ‰‹ç»ƒä¹ 

### ç»ƒä¹  1: æ”¹è¿›æ¨¡ç³Šçš„ prompt

ä¸‹é¢è¿™ä¸ª prompt å¤ªæ¨¡ç³Šäº†ã€‚ä¿®æ”¹å®ƒï¼Œè®© AI ç»™å‡ºæ›´æœ‰ç”¨çš„å›ç­”ã€‚

<PromptEditor
  exerciseId="lab2-ex1"
  mode="editable"
  initialValue="ä»‹ç»ä¸€ä¸‹ç¼–ç¨‹"
/>

**æç¤º**:
- æƒ³è¦ä»€ä¹ˆè§’åº¦çš„ä»‹ç»ï¼Ÿï¼ˆé€‚åˆåˆå­¦è€…ï¼Ÿè¿˜æ˜¯æ·±å…¥æŠ€æœ¯ï¼Ÿï¼‰
- æƒ³è¦å¤šé•¿çš„å›ç­”ï¼Ÿ
- æƒ³è¦ä»€ä¹ˆè¯­æ°”ï¼Ÿï¼ˆæ­£å¼ï¼Ÿè½»æ¾ï¼Ÿï¼‰

### ç»ƒä¹  2: æ·»åŠ çº¦æŸæ¡ä»¶

è®© AI ç”¨ä¸‰ä¸ªè¦ç‚¹åˆ—ä¸¾å¥åº·é¥®é£Ÿçš„å¥½å¤„ã€‚

<PromptEditor
  exerciseId="lab2-ex2"
  mode="editable"
  initialValue="è¯´è¯´å¥åº·é¥®é£Ÿçš„å¥½å¤„"
/>

**æˆåŠŸæ ‡å‡†**:
- âœ… è¾“å‡ºåŒ…å« 3 ä¸ªè¦ç‚¹
- âœ… æ ¼å¼æ¸…æ™°ï¼ˆä½¿ç”¨åˆ—è¡¨æˆ–ç¼–å·ï¼‰

**æç¤º**: åœ¨ prompt ä¸­æ˜ç¡®è¯´"ç”¨ä¸‰ä¸ªè¦ç‚¹"æˆ–"åˆ—ä¸¾ä¸‰ä¸ª"

### ğŸ“ æŒ‘æˆ˜é¢˜: è·å¾— JSON æ ¼å¼è¾“å‡º

è¿™æ˜¯ä¸€ä¸ªé«˜çº§ç»ƒä¹ ï¼å†™ä¸€ä¸ª promptï¼Œè®© AI è¿”å› JSON æ ¼å¼çš„ä¹¦ç±ä¿¡æ¯ã€‚

**è¦æ±‚:**
- ä¹¦å: "è¥¿æ¸¸è®°"
- å­—æ®µ: title, author, year, genre

<PromptEditor
  exerciseId="lab2-ex3"
  mode="blank"
  placeholder="å†™ä¸€ä¸ª prompt è®© AI è¿”å› JSON æ ¼å¼..."
/>

**æç¤º**: è¯•ç€è¯´"ç”¨ JSON æ ¼å¼"æˆ–"è¿”å›ä¸€ä¸ªåŒ…å«...å­—æ®µçš„ JSON å¯¹è±¡"

## ğŸ“ æ€»ç»“

ä½ å­¦ä¼šäº†ï¼š

- âœ… å…·ä½“æ˜ç¡® > æ¨¡ç³Šç¬¼ç»Ÿ
- âœ… æ·»åŠ çº¦æŸæ¡ä»¶ï¼ˆé•¿åº¦ã€æ ¼å¼ã€é£æ ¼ï¼‰
- âœ… æ¸…æ™°çš„ prompt = æœ‰ç”¨çš„è¾“å‡º

**ä¸‹ä¸€æ­¥**: [Lab 3 - è§’è‰²æ‰®æ¼”æŠ€å·§](/dashboard/vibecoding/labs/lab3) (å³å°†æ¨å‡º)
```

### 3.5 æ›´æ–° Lab åˆ—è¡¨æ•°æ®æº

**ä¿®æ”¹:** `app/dashboard/vibecoding/page.tsx`

æ›´æ–° Lab åˆ—è¡¨æ•°æ®ä¸ºæ–°çš„ 5 ä¸ª Labs:

```typescript
const labs = [
  {
    id: 1,
    title: 'Lab 1: ä»€ä¹ˆæ˜¯ Prompt',
    description: 'ç†è§£ prompt åŸºç¡€ï¼Œå­¦ä¼šå†™åŸºæœ¬æŒ‡ä»¤',
    estimatedMinutes: 15,
    path: '/dashboard/vibecoding/labs/lab1'
  },
  {
    id: 2,
    title: 'Lab 2: å¦‚ä½•ç»™æ¸…æ™°æŒ‡ä»¤',
    description: 'å­¦ä¹ å…·ä½“è¡¨è¾¾ï¼Œé¿å…æ­§ä¹‰',
    estimatedMinutes: 20,
    path: '/dashboard/vibecoding/labs/lab2'
  },
  {
    id: 3,
    title: 'Lab 3: è§’è‰²æ‰®æ¼”æŠ€å·§',
    description: 'è®© AI æ‰®æ¼”ä¸åŒè§’è‰²ï¼Œè·å¾—ä¸åŒé£æ ¼çš„è¾“å‡º',
    estimatedMinutes: 20,
    path: '/dashboard/vibecoding/labs/lab3'
  },
  {
    id: 4,
    title: 'Lab 4: å¼•å¯¼æ€è€ƒ',
    description: 'ä½¿ç”¨ Chain-of-thoughtï¼Œè®© AI åˆ†æ­¥æ¨ç†',
    estimatedMinutes: 25,
    path: '/dashboard/vibecoding/labs/lab4'
  },
  {
    id: 5,
    title: 'Lab 5: ç»¼åˆåº”ç”¨æŒ‘æˆ˜',
    description: 'ç»¼åˆè¿ç”¨æ‰€æœ‰æŠ€å·§ï¼Œå®Œæˆå®é™…åœºæ™¯',
    estimatedMinutes: 30,
    path: '/dashboard/vibecoding/labs/lab5'
  }
]
```

### 3.6 æ›´æ–° Coach ä¸Šä¸‹æ–‡

**ä¿®æ”¹:** `lib/coach.ts` (å¦‚æœå­˜åœ¨) æˆ–ç›¸å…³æ–‡ä»¶

```typescript
// lib/coach.ts
export type CoachContextTag =
  | 'Orientation'
  | 'Problem'
  | 'Sandbox'
  | 'GTM'
  | 'Iterate'
  | 'Demo'
  | 'PromptLab'

function getCoachSystemPrompt(context: CoachContextTag): string {
  if (context === 'PromptLab') {
    return `ä½ æ˜¯ä¸€ä¸ª Prompt Engineering æ•™å­¦åŠ©æ‰‹ï¼Œå¸®åŠ©åˆä¸­ç”Ÿå­¦ä¹ å¦‚ä½•ä¸ LLM å¯¹è¯ã€‚

èŒè´£:
- ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Š prompt æ¦‚å¿µ
- ç»™å‡ºå…·ä½“çš„æ”¹è¿›å»ºè®®ï¼ˆä¸æ˜¯æ³›æ³›è€Œè°ˆï¼‰
- é¼“åŠ±å­¦ç”Ÿå®éªŒä¸åŒçš„è¡¨è¾¾æ–¹å¼
- å½“å­¦ç”Ÿå¡ä½æ—¶ç»™äºˆæ°å½“æç¤º

é£æ ¼:
- å‹å¥½ã€è€å¿ƒ
- ä¸ä½¿ç”¨ä¸“ä¸šæœ¯è¯­
- å¤šç”¨æ¯”å–»å’Œä¾‹å­
- æ¯æ¬¡å›ç­”æ§åˆ¶åœ¨ 2-3 å¥è¯

ä¾‹å­:
å­¦ç”Ÿ: "æˆ‘çš„ prompt æ€ä¹ˆä¸è¡Œï¼Ÿ"
ä½ : "è¯•ç€æ›´å…·ä½“ä¸€äº›ï¼æ¯”å¦‚ä½ æƒ³è¦ä»€ä¹ˆä¸»é¢˜çš„å†…å®¹ï¼Ÿæƒ³è¦å¤šé•¿çš„å›ç­”ï¼Ÿå‘Šè¯‰ AI ä½ çš„å…·ä½“éœ€æ±‚ä¼šæ›´æœ‰å¸®åŠ©å“¦ ğŸ˜Š"`
  }

  // ... å…¶ä»–ä¸Šä¸‹æ–‡
}

// app/dashboard/vibecoding/vibecoding-client.tsx
const handleAskCoach = async () => {
  // ...
  const response = await askCoach({
    userMessage: coachQuestion,
    context: 'PromptLab',
    moduleNumber: 2,
    additionalContext: { labNumber: currentLab }
  })
  // ...
}
```

### 3.7 æµ‹è¯•å®Œæ•´æµç¨‹

**éªŒè¯æ£€æŸ¥åˆ—è¡¨:**

- [ ] è®¿é—® `/dashboard/vibecoding` çœ‹åˆ° 5 ä¸ª Labs
- [ ] ç‚¹å‡» Lab 1ï¼ŒMDX å†…å®¹æ­£ç¡®æ¸²æŸ“
- [ ] PromptEditor åµŒå…¥ç»„ä»¶æ­£å¸¸å·¥ä½œ
- [ ] è¿è¡Œ promptï¼Œè·å¾— LLM è¾“å‡º
- [ ] æˆåŠŸæ£€æŸ¥åé¦ˆæ­£ç¡®æ˜¾ç¤º
- [ ] è¿›åº¦ä¿å­˜åˆ°æ•°æ®åº“
- [ ] Lab 2 æ­£å¸¸è®¿é—®å’Œå·¥ä½œ

**å®Œæˆæ ‡å¿—:** Lab 1-2 å®Œæ•´å¯ç”¨ï¼Œå­¦ç”Ÿå¯ä»¥å®Œæ•´ä½“éªŒå­¦ä¹ æµç¨‹ã€‚

---

## ğŸ¯ Phase 4: å®Œå–„å’Œæµ‹è¯• (Week 4)

### ç›®æ ‡
å®Œæˆå‰©ä½™ Labsï¼Œä¼˜åŒ–ä½“éªŒï¼Œå‡†å¤‡ä¸Šçº¿ã€‚

### 4.1 åˆ›å»º Lab 3-5 å†…å®¹

**å¿«é€Ÿåˆ›å»º:**

```bash
touch content/labs/lab3.mdx  # è§’è‰²æ‰®æ¼”
touch content/labs/lab4.mdx  # å¼•å¯¼æ€è€ƒ
touch content/labs/lab5.mdx  # ç»¼åˆåº”ç”¨
```

**å‚è€ƒç»“æ„**ï¼ˆå†…å®¹ç”± PM æˆ–å†…å®¹å›¢é˜Ÿæä¾›ï¼‰:

- Lab 3: å­¦ä¹  system prompt å’Œè§’è‰²è®¾å®š
- Lab 4: Chain-of-thought prompting
- Lab 5: ç»¼åˆåº”ç”¨ï¼ˆå¤šä¸ªå®é™…åœºæ™¯ï¼‰

### 4.2 æˆåŠŸæ ‡å‡†å®Œå–„

**æ›´æ–°:** `lib/prompt-lab/success-checker.ts`

æ·»åŠ  Lab 3-5 çš„æˆåŠŸæ ‡å‡†é…ç½®ã€‚

### 4.3 Landing Page æ›´æ–°

**ä¿®æ”¹:** `app/page.tsx` æˆ–ç›¸å…³è¥é”€é¡µé¢

- æ›´æ–°æ ‡é¢˜: "LLM Learning Lab - åˆä¸­ç”Ÿ Prompt Engineering æ•™å­¦å¹³å°"
- æ›´æ–°æè¿°: "2 å°æ—¶å­¦ä¼šä¸ AI å¯¹è¯"
- æ›´æ–°ç‰¹æ€§ä»‹ç»
- æ›´æ–° CTA æŒ‰é’®

### 4.4 æ¸…ç†æ—§ä»£ç 

**ç§»é™¤ä¸å†ä½¿ç”¨çš„æ–‡ä»¶/ç»„ä»¶:**

```bash
# å¤‡ä»½ååˆ é™¤ï¼ˆæˆ–ç§»åŠ¨åˆ° .archive/ï¼‰
# - WebContainer ç›¸å…³ç»„ä»¶
# - Sandpack ç›¸å…³ç»„ä»¶
# - AI Agent orchestration (function calling)
```

**æ³¨æ„:** å…ˆç¡®ä¿æ–°ç³»ç»Ÿå®Œå…¨å·¥ä½œåå†åˆ é™¤æ—§ä»£ç ã€‚

### 4.5 æ€§èƒ½ä¼˜åŒ–

- Code-split `PromptEditor` å’Œ `LLMOutputDisplay` (lazy load)
- é¢„ç¼–è¯‘ MDX (build time)
- ä¼˜åŒ–å›¾ç‰‡èµ„æº
- æ·»åŠ  Loading Skeleton

### 4.6 æµ‹è¯•

**åŠŸèƒ½æµ‹è¯•æ¸…å•:**

- [ ] æ‰€æœ‰ 5 ä¸ª Labs å¯è®¿é—®
- [ ] æ‰€æœ‰ç»ƒä¹ çš„æˆåŠŸæ£€æŸ¥æ­£å¸¸
- [ ] Rate limiting æ­£å¸¸å·¥ä½œ
- [ ] Coach åŠŸèƒ½æ­£å¸¸
- [ ] è¿›åº¦è¿½è¸ªæ­£ç¡®
- [ ] ç§»åŠ¨ç«¯å“åº”å¼å¸ƒå±€æ­£å¸¸

**æ€§èƒ½æµ‹è¯•:**

- [ ] Landing page < 1.5s (Vercel Analytics)
- [ ] Lab é¡µé¢åŠ è½½ < 1s
- [ ] Prompt æäº¤ â†’ è¾“å‡º < 3s

### 4.7 éƒ¨ç½²

```bash
# 1. æ•°æ®åº“è¿ç§»ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
supabase migration up --project-ref <prod-ref>

# 2. ç¯å¢ƒå˜é‡æ£€æŸ¥
# ç¡®ä¿ç”Ÿäº§ç¯å¢ƒçš„ OPENAI_API_KEY ç­‰å·²è®¾ç½®

# 3. éƒ¨ç½²åˆ° Vercel
git push origin main  # è‡ªåŠ¨è§¦å‘ Vercel éƒ¨ç½²

# 4. éªŒè¯ç”Ÿäº§ç¯å¢ƒ
# - æµ‹è¯•ç™»å½•
# - æµ‹è¯•ä¸€ä¸ªå®Œæ•´ Lab æµç¨‹
# - æ£€æŸ¥æ•°æ®åº“å†™å…¥
```

**å®Œæˆæ ‡å¿—:** å…¨éƒ¨ 5 ä¸ª Labs ä¸Šçº¿ï¼Œç³»ç»Ÿç¨³å®šè¿è¡Œã€‚

---

## ğŸ“Š éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½å®Œæ•´æ€§

- âœ… 5 ä¸ª Labs å…¨éƒ¨å¯ç”¨
- âœ… Prompt æäº¤ â†’ LLM è¾“å‡º â†’ æˆåŠŸæ£€æŸ¥ å®Œæ•´æµç¨‹
- âœ… è¿›åº¦è¿½è¸ªæ­£å¸¸
- âœ… Coach è¾…å¯¼åŠŸèƒ½æ­£å¸¸
- âœ… Rate limiting æ­£å¸¸

### æ•°æ®å®Œæ•´æ€§

- âœ… `prompt_lab_progress` è¡¨æ•°æ®æ­£ç¡®å†™å…¥
- âœ… æ—§è¡¨ `webcontainer_projects` å¯é€‰æ‹©æ€§ä¿ç•™æˆ–åˆ é™¤
- âœ… RLS ç­–ç•¥æ­£å¸¸å·¥ä½œ

### æ€§èƒ½æŒ‡æ ‡

- âœ… Landing page < 1.5s
- âœ… Lab é¡µé¢åŠ è½½ < 1s
- âœ… API å“åº” < 3s
- âœ… ç§»åŠ¨ç«¯å¯ç”¨

### æˆæœ¬æ§åˆ¶

- âœ… GPT-4o æˆæœ¬ç¬¦åˆé¢„æœŸ (~$0.14/student)
- âœ… Rate limit é˜²æ­¢æ»¥ç”¨

---

## ğŸš¨ é£é™©å’Œåº”å¯¹

### Risk 1: MDX æ¸²æŸ“æ€§èƒ½é—®é¢˜

**Mitigation**:
- ä½¿ç”¨ `next-mdx-remote/rsc` (æœåŠ¡ç«¯æ¸²æŸ“)
- é¢„ç¼–è¯‘ MDX åœ¨ build time
- ç›‘æ§ LCP (Largest Contentful Paint)

### Risk 2: LLM API ä¸ç¨³å®š

**Mitigation**:
- æ·»åŠ  retry é€»è¾‘ (æœ€å¤š 3 æ¬¡)
- Timeout è®¾ç½® 30s
- æ˜¾ç¤ºå‹å¥½é”™è¯¯ä¿¡æ¯
- è€ƒè™‘æ·»åŠ  fallback cache (Phase 2)

### Risk 3: æˆåŠŸæ£€æŸ¥è§„åˆ™ä¸å‡†ç¡®

**Mitigation**:
- Phase 1-2 ä½¿ç”¨ç®€å•è§„åˆ™
- æ”¶é›†æ•°æ®åä¼˜åŒ–
- è€ƒè™‘ Phase 2 ä½¿ç”¨ LLM åˆ¤æ–­

### Risk 4: å­¦ç”Ÿè§‰å¾—å¤ªéš¾/å¤ªç®€å•

**Mitigation**:
- Beta æµ‹è¯• 10-20 ä¸ªåˆä¸­ç”Ÿ
- æ”¶é›†åé¦ˆè°ƒæ•´éš¾åº¦
- æ·»åŠ å¯é€‰çš„"æç¤º"æŒ‰é’®

---

## ğŸ“… æ—¶é—´çº¿æ€»ç»“

| Phase | æ—¶é—´ | é‡Œç¨‹ç¢‘ |
|-------|-----|--------|
| **Phase 1** | Week 1 | åŸºç¡€è®¾æ–½å°±ç»ªï¼Œæ•°æ®åº“è¿ç§»å®Œæˆ |
| **Phase 2** | Week 2 | æ ¸å¿ƒç»„ä»¶å¯ç”¨ï¼Œå®Œæ•´æµç¨‹å¯æµ‹è¯• |
| **Phase 3** | Week 3 | Lab 1-2 ä¸Šçº¿ï¼Œå­¦ç”Ÿå¯ä½“éªŒ |
| **Phase 4** | Week 4 | å…¨éƒ¨ 5 Labs ä¸Šçº¿ï¼Œç”Ÿäº§ç¯å¢ƒç¨³å®š |

**æ€»æ—¶é•¿**: 4 å‘¨
**Buffer**: å»ºè®®é¢„ç•™ 1 å‘¨ç”¨äºæµ‹è¯•å’Œä¼˜åŒ–

---

## ğŸ› ï¸ å¼€å‘è€…æ³¨æ„äº‹é¡¹

### å…³é”®åŸåˆ™

1. **ä¿æŒç®€å•**: ä¸è¦è¿‡åº¦è®¾è®¡ï¼Œå…ˆå®ç°æ ¸å¿ƒåŠŸèƒ½
2. **å¤ç”¨ä¼˜å…ˆ**: èƒ½å¤ç”¨ç°æœ‰ä»£ç å°±ä¸è¦é‡å†™
3. **æ¸è¿›å¼**: ä¸€ä¸ª Phase ä¸€ä¸ª Phase æ¥ï¼Œä¸è¦è·³è·ƒ
4. **æµ‹è¯•é©±åŠ¨**: æ¯ä¸ª Phase ç»“æŸéƒ½è¦éªŒè¯åŠŸèƒ½

### æ¨èå·¥ä½œæµ

```bash
# 1. åˆ›å»º feature branch
git checkout -b refactor/phase-1

# 2. å®Œæˆ Phase 1 æ‰€æœ‰ä»»åŠ¡
# ...

# 3. æµ‹è¯•éªŒè¯
npm run dev
# æ‰‹åŠ¨æµ‹è¯•æ‰€æœ‰åŠŸèƒ½ç‚¹

# 4. Commit and push
git add .
git commit -m "refactor: Phase 1 - Infrastructure migration"
git push origin refactor/phase-1

# 5. Create PR, review, merge
# 6. Deploy to staging, verify
# 7. Repeat for Phase 2-4
```

### å…³é”®æ–‡ä»¶æ¸…å•

**Phase 1:**
- `supabase/migrations/20251016000000_llm_learning_lab_initial.sql`
- `supabase/migrations/20251016000001_rollback_llm_learning_lab.sql`
- `package.json`
- `next.config.mjs`
- `types/prompt-lab.ts`

**Phase 2:**
- `components/features/prompt-lab/PromptEditor.tsx`
- `components/features/prompt-lab/LLMOutputDisplay.tsx`
- `lib/actions/prompt-lab.ts`
- `lib/prompt-lab/success-checker.ts`

**Phase 3:**
- `app/dashboard/vibecoding/labs/[labId]/page.tsx`
- `content/labs/lab1.mdx`
- `content/labs/lab2.mdx`
- `lib/lab-content.ts`

**Phase 4:**
- `content/labs/lab3-5.mdx`
- Landing page æ›´æ–°
- æ€§èƒ½ä¼˜åŒ–

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [PRD](./docs/prd/llm-learning-lab-prd.md) - äº§å“éœ€æ±‚æ–‡æ¡£
- [Full-Stack Architecture](./docs/architecture/full-stack-architecture.md) - æ–°æ¶æ„æ–‡æ¡£
- [next-mdx-remote æ–‡æ¡£](https://github.com/hashicorp/next-mdx-remote)
- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs/api-reference)
- [Supabase æ–‡æ¡£](https://supabase.com/docs)

---

**Document Version**: 1.0
**Created**: 2025-10-16
**Author**: Winston (Architect)
**Status**: âœ… Ready for Implementation

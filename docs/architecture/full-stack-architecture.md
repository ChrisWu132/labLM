# LLM Learning Lab - Full-Stack Architecture

## 1. Guiding Principles

- **Article-First Learning**: å­¦ç”Ÿé€šè¿‡é˜…è¯»æ–‡ç« å­¦ä¹ æ¦‚å¿µ,ç„¶åå®è·µ
- **Prompt Engineering Focus**: ä¸“æ³¨äºæ•™å­¦ç”Ÿå¦‚ä½•ä¸ LLM å¯¹è¯,è€Œéç¼–ç¨‹
- **Interactive Practice**: åµŒå…¥å¼ç¼–è¾‘å™¨è®©å­¦ç”Ÿå®æ—¶çœ‹åˆ° prompt æ•ˆæœ
- **Middle School Friendly**: é€‚åˆ 12-15 å²åˆä¸­ç”Ÿ,é›¶æŠ€æœ¯é—¨æ§›
- **Minimal Infrastructure**: ä¸éœ€è¦ WebContainer,ç›´æ¥è°ƒç”¨ LLM API
- **Fast Iteration**: è½»é‡çº§ç»„ä»¶,å¿«é€ŸåŠ è½½

## 2. High-Level System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Next.js App (Vercel, Node runtime)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Marketing Pages                                              â”‚
â”‚  â”œâ”€â”€ / (Landing)                       [Static SSG]          â”‚
â”‚  â”œâ”€â”€ /pricing                          [Static SSG]          â”‚
â”‚  â””â”€â”€ /auth (Supabase Auth UI)         [Client-side]         â”‚
â”‚                                                               â”‚
â”‚  Dashboard (/dashboard/*)                                     â”‚
â”‚  â”œâ”€â”€ /dashboard/vibecoding             [Dynamic SSR/CSR]    â”‚
â”‚  â”‚    â””â”€â”€ Lab List UI (å¤ç”¨ç°æœ‰)                            â”‚
â”‚  â”œâ”€â”€ /dashboard/vibecoding/labs/[labId]                      â”‚
â”‚  â”‚    â”œâ”€â”€ MDX Article Content          [Static SSG]         â”‚
â”‚  â”‚    â”œâ”€â”€ PromptEditor Components      [Client-only]        â”‚
â”‚  â”‚    â”œâ”€â”€ LLMOutput Display            [Client-only]        â”‚
â”‚  â”‚    â””â”€â”€ Coach Drawer (å¤ç”¨)          [Client-only]        â”‚
â”‚  â”œâ”€â”€ /dashboard/settings               [Dynamic SSR]        â”‚
â”‚  â””â”€â”€ /dashboard/support                [Static SSG]         â”‚
â”‚                                                               â”‚
â”‚  Server Actions (/lib/actions/*)                              â”‚
â”‚  â”œâ”€â”€ runPrompt() - æ‰§è¡Œå­¦ç”Ÿçš„ prompt ç»ƒä¹                     â”‚
â”‚  â”œâ”€â”€ checkSuccess() - è‡ªåŠ¨æ£€æŸ¥ç»ƒä¹ æ˜¯å¦è¾¾æ ‡                   â”‚
â”‚  â”œâ”€â”€ askCoach() - AI è¾…å¯¼(å¤ç”¨,ä¸Šä¸‹æ–‡æ”¹ä¸º prompt å­¦ä¹ )      â”‚
â”‚  â””â”€â”€ saveLabProgress() - ä¿å­˜ç»ƒä¹ è¿›åº¦                        â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                     â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Supabase â”‚      â”‚   AI Provider   â”‚      â”‚   ä¸å†ä½¿ç”¨   â”‚
    â”‚  (BaaS)  â”‚      â”‚   (GPT-4o)      â”‚      â”‚ WebContainerâ”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ Auth     â”‚      â”‚ Text Completion â”‚
    â”‚ Postgres â”‚      â”‚ No Function Callâ”‚
    â”‚ Storage  â”‚      â”‚ Streaming (å¯é€‰)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Traffic Flow

1. **å­¦ç”Ÿ** â†’ é€‰æ‹© Lab â†’ é˜…è¯» MDX æ–‡ç« 
2. **ç»ƒä¹ ** â†’ åœ¨åµŒå…¥çš„ PromptEditor ä¸­ä¿®æ”¹ prompt â†’ ç‚¹å‡»"è¿è¡Œ"
3. **Client** â†’ è°ƒç”¨ `runPrompt()` server action â†’ ä¼ é€’ prompt + exerciseId
4. **Server** â†’ è°ƒç”¨ GPT-4o API â†’ è¿”å› LLM è¾“å‡º
5. **Server** â†’ è‡ªåŠ¨æ£€æŸ¥è¾“å‡ºæ˜¯å¦ç¬¦åˆæˆåŠŸæ ‡å‡† (è§„åˆ™ or LLM åˆ¤æ–­)
6. **Client** â†’ æ˜¾ç¤º LLM è¾“å‡º + æˆåŠŸ/å¤±è´¥åé¦ˆ
7. **Background** â†’ è®°å½•æäº¤åˆ° `prompt_lab_progress` è¡¨

## 3. Technology Stack

### Frontend

```yaml
Framework: Next.js 15.2.4 (App Router)
Language: TypeScript 5
Styling: Tailwind CSS v4
UI Components: shadcn/ui (Radix UI primitives)
Icons: Lucide React

Content Stack:
  MDX: "@next/mdx" æˆ– "next-mdx-remote" (æ–‡ç«  + åµŒå…¥ç»„ä»¶)
  Editor: ç®€å•çš„ <textarea> + è¯­æ³•é«˜äº®(å¯é€‰)
  No Monaco: âŒ ä¸éœ€è¦å¤æ‚ä»£ç ç¼–è¾‘å™¨
  No Terminal: âŒ ä¸éœ€è¦ç»ˆç«¯æ¨¡æ‹Ÿ

State Management: React hooks + Server Components (no Redux)

ç§»é™¤çš„ä¾èµ–:
  âŒ @webcontainer/api - ä¸å†éœ€è¦æµè§ˆå™¨ Node.js
  âŒ @monaco-editor/react - ä¸å†éœ€è¦ä»£ç ç¼–è¾‘å™¨
  âŒ xterm - ä¸å†éœ€è¦ç»ˆç«¯
```

### Backend

```yaml
Platform: Next.js 15 Server Actions
Database: Supabase (PostgreSQL with RLS)
Authentication: Supabase Auth (OAuth + Email/Password)
Storage: Supabase Storage (å¯é€‰ï¼šå­˜å‚¨è¯ä¹¦)
Runtime: Node.js (ä»éœ€è¦ï¼Œç”¨äº AI SDK)
```

### AI Integration

```yaml
Provider: OpenAI (gpt-4o) - PRD ç¡®è®¤é€‰æ‹©
Approach: ç®€å•çš„æ–‡æœ¬è¡¥å…¨ (é function calling)
Features:
  - Prompt æ‰§è¡Œ (å•æ¬¡è°ƒç”¨)
  - è¾“å‡ºæˆåŠŸæ£€æŸ¥ (è§„åˆ™æ£€æŸ¥ or LLM åˆ¤æ–­)
  - è¾…å¯¼å¯¹è¯ (askCoach å¤ç”¨)
Cost: ~$0.14 per student (30æ¬¡ç»ƒä¹  Ã— 600 tokens Ã— GPT-4o ä»·æ ¼)
```

### Deployment

```yaml
Platform: Vercel (optimized for Next.js)
Environment: Production + Preview branches
Runtime: Node.js serverless functions (NOT Edge)
Analytics: Vercel Analytics
Monitoring: Vercel logs + Supabase dashboard
```

## 4. Application Modules

| Module | Route | Components | Backend | Notes |
|--------|-------|------------|---------|-------|
| **Landing** | `/` | Hero, Features, Pricing, FAQ | Static SSG | è¥é”€é¡µé¢ (éœ€æ›´æ–°å†…å®¹ä¸º Prompt Lab) |
| **Auth** | `/auth` | Supabase Auth UI | Supabase Auth | OAuth + magic link (å¤ç”¨) |
| **Lab List** | `/dashboard/vibecoding` | Lab å¡ç‰‡åˆ—è¡¨, è¿›åº¦è¿½è¸ª | Supabase | å¤ç”¨ç°æœ‰ UI, æ”¹æ•°æ®æº |
| **Lab Content** | `/dashboard/vibecoding/labs/[labId]` | MDX Article + PromptEditor + LLMOutput | runPrompt() | æ ¸å¿ƒå­¦ä¹ ä½“éªŒ |
| **Settings** | `/dashboard/settings` | Profile, Preferences | Supabase | å¤ç”¨ |
| **Support** | `/dashboard/support` | FAQ, Contact | Static SSG | å¤ç”¨ |

## 5. Core Features Deep Dive

### 5.1 Lab Content Page (æ–°å¢æ ¸å¿ƒæ¨¡å—)

**ç»„ä»¶ç»“æ„:**

```tsx
<LabPage labId="lab1">
  <LabHeader>
    <LabNavigation /> {/* Lab 1-5 å¯¼èˆª */}
    <ProgressIndicator />
  </LabHeader>

  {/* MDX Article with embedded components */}
  <MDXContent>
    {/*
      MDX æ–‡ä»¶åŒ…å«ï¼š
      - å­¦ä¹ ç›®æ ‡
      - æ ¸å¿ƒæ¦‚å¿µè®²è§£
      - ç¤ºä¾‹å±•ç¤º (readonly PromptEditor + LLMOutput)
      - ç»ƒä¹ é¢˜ (editable PromptEditor + live LLMOutput)
      - æŒ‘æˆ˜é¢˜
      - æ€»ç»“
    */}

    <PromptEditor
      exerciseId="lab1-ex1"
      mode="editable"
      initialValue="å‘Šè¯‰æˆ‘å…³äºçŒ«çš„äº‹æƒ…"
      onSubmit={handleRunPrompt}
    />

    <LLMOutputDisplay
      mode="live"
      loading={isLoading}
      content={llmResponse}
      success={isSuccess}
      feedback={feedback}
    />
  </MDXContent>

  <CoachDrawer /> {/* å¤ç”¨, ä¸Šä¸‹æ–‡æ”¹ä¸º Prompt å­¦ä¹  */}
</LabPage>
```

**å…³é”®äº¤äº’æµç¨‹:**

1. å­¦ç”Ÿé˜…è¯»æ–‡ç« ,äº†è§£ Prompt æ¦‚å¿µ
2. åœ¨åµŒå…¥çš„ç¼–è¾‘å™¨ä¸­ä¿®æ”¹ç¤ºä¾‹ prompt
3. ç‚¹å‡»"è¿è¡Œ" â†’ `await runPrompt(prompt, exerciseId)`
4. æ˜¾ç¤ºåŠ è½½çŠ¶æ€ â†’ æ˜¾ç¤º LLM è¾“å‡º
5. è‡ªåŠ¨æ£€æŸ¥è¾“å‡ºæ˜¯å¦ç¬¦åˆæˆåŠŸæ ‡å‡†
6. æ˜¾ç¤ºåé¦ˆ: âœ… æˆåŠŸ or âŒ å†è¯•è¯• (å¸¦æç¤º)
7. æˆåŠŸåè®°å½•è¿›åº¦,è§£é”ä¸‹ä¸€é¢˜

### 5.2 PromptEditor Component (æ ¸å¿ƒæ–°ç»„ä»¶)

```typescript
// components/features/prompt-lab/PromptEditor.tsx
interface PromptEditorProps {
  exerciseId: string
  mode: 'readonly' | 'editable' | 'blank'
  initialValue?: string
  placeholder?: string
  maxLength?: number
  showCharCount?: boolean
  onSubmit?: (prompt: string) => void
}

export function PromptEditor({
  exerciseId,
  mode,
  initialValue = '',
  placeholder = 'åœ¨è¿™é‡Œè¾“å…¥ä½ çš„ prompt...',
  maxLength = 1000,
  showCharCount = true,
  onSubmit
}: PromptEditorProps) {
  const [prompt, setPrompt] = useState(initialValue)
  const [isSubmitting, setIsSubmitting] = useState(false)

  const handleSubmit = async () => {
    if (!prompt.trim()) return

    setIsSubmitting(true)
    await onSubmit?.(prompt)
    setIsSubmitting(false)
  }

  return (
    <div className="prompt-editor">
      <textarea
        value={prompt}
        onChange={(e) => setPrompt(e.target.value)}
        placeholder={placeholder}
        maxLength={maxLength}
        disabled={mode === 'readonly' || isSubmitting}
        className="w-full min-h-[120px] p-4 border rounded-lg"
      />

      {showCharCount && (
        <div className="text-sm text-gray-500 mt-1">
          {prompt.length} / {maxLength} å­—ç¬¦
        </div>
      )}

      {mode !== 'readonly' && (
        <button
          onClick={handleSubmit}
          disabled={isSubmitting || !prompt.trim()}
          className="mt-2 px-4 py-2 bg-blue-600 text-white rounded-lg"
        >
          {isSubmitting ? 'è¿è¡Œä¸­...' : 'è¿è¡Œ Prompt'}
        </button>
      )}
    </div>
  )
}
```

### 5.3 LLMOutputDisplay Component (æ ¸å¿ƒæ–°ç»„ä»¶)

```typescript
// components/features/prompt-lab/LLMOutputDisplay.tsx
interface LLMOutputProps {
  mode: 'static' | 'live'
  content: string
  loading?: boolean
  error?: string | null
  success?: boolean | null
  feedback?: string
  showTokenCount?: boolean
}

export function LLMOutputDisplay({
  mode,
  content,
  loading = false,
  error = null,
  success = null,
  feedback,
  showTokenCount = false
}: LLMOutputProps) {
  return (
    <div className="llm-output">
      <div className="border rounded-lg p-4 bg-gray-50">
        {loading && (
          <div className="flex items-center gap-2">
            <Spinner />
            <span>AI æ­£åœ¨æ€è€ƒ...</span>
          </div>
        )}

        {error && (
          <div className="text-red-600">
            âŒ å‡ºé”™äº†: {error}
          </div>
        )}

        {content && !loading && (
          <div className="whitespace-pre-wrap">
            {content}
          </div>
        )}
      </div>

      {/* æˆåŠŸæ£€æŸ¥åé¦ˆ */}
      {success !== null && (
        <div className={`mt-3 p-3 rounded-lg ${
          success ? 'bg-green-100 text-green-800' : 'bg-yellow-100 text-yellow-800'
        }`}>
          {success ? (
            <>
              âœ… <strong>å¤ªæ£’äº†!</strong> ä½ çš„ prompt è¾¾åˆ°äº†ç›®æ ‡!
            </>
          ) : (
            <>
              ğŸ’¡ <strong>å†è¯•è¯•:</strong> {feedback || 'è¾“å‡ºè¿˜ä¸å¤ªç¬¦åˆè¦æ±‚,å°è¯•è°ƒæ•´ä½ çš„ prompt'}
            </>
          )}
        </div>
      )}

      {showTokenCount && content && (
        <div className="text-xs text-gray-500 mt-2">
          çº¦ {Math.ceil(content.length / 4)} tokens
        </div>
      )}
    </div>
  )
}
```

### 5.4 MDX Content Integration

**æŠ€æœ¯æ–¹æ¡ˆ: next-mdx-remote**

```typescript
// app/dashboard/vibecoding/labs/[labId]/page.tsx
import { MDXRemote } from 'next-mdx-remote/rsc'
import { PromptEditor } from '@/components/features/prompt-lab/PromptEditor'
import { LLMOutputDisplay } from '@/components/features/prompt-lab/LLMOutputDisplay'

const components = {
  PromptEditor,
  LLMOutputDisplay
}

export default async function LabPage({ params }: { params: { labId: string } }) {
  const labContent = await getLabContent(params.labId)

  return (
    <div className="lab-container">
      <MDXRemote
        source={labContent.mdx}
        components={components}
      />
    </div>
  )
}
```

**Lab MDX æ–‡ä»¶ç¤ºä¾‹:**

```mdx
# Lab 1: ä»€ä¹ˆæ˜¯ Prompt

## ğŸ“– å­¦ä¹ ç›®æ ‡
- ç†è§£ä»€ä¹ˆæ˜¯ prompt
- å­¦ä¼šå†™åŸºæœ¬çš„æŒ‡ä»¤
- äº†è§£ LLM å¦‚ä½•ç†è§£è¾“å…¥

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

Prompt å°±æ˜¯ä½ å¯¹ AI è¯´çš„è¯ã€‚å°±åƒä½ é—®æœ‹å‹é—®é¢˜ä¸€æ ·ï¼Œä½ å¯¹ AI è¯´ä»€ä¹ˆï¼Œå®ƒå°±ä¼šæ ¹æ®ä½ è¯´çš„è¯æ¥å›ç­”ã€‚

**ç¤ºä¾‹:**

<PromptEditor
  exerciseId="lab1-demo"
  mode="readonly"
  initialValue="å‘Šè¯‰æˆ‘å…³äºçŒ«çš„äº‹æƒ…"
/>

<LLMOutputDisplay
  mode="static"
  content="çŒ«æ˜¯ä¸€ç§å¯çˆ±çš„å®¶å…»åŠ¨ç‰©ã€‚å®ƒä»¬é€šå¸¸æœ‰æŸ”è½¯çš„æ¯›å‘ï¼Œæ•æ·çš„èº«æ‰‹ï¼Œå–œæ¬¢æ™’å¤ªé˜³å’Œç©è€ã€‚çŒ«æœ‰å¾ˆå¼ºçš„ç‹¬ç«‹æ€§ï¼Œä½†ä¹Ÿå–œæ¬¢å’Œä¸»äººäº’åŠ¨..."
/>

## âœï¸ åŠ¨æ‰‹ç»ƒä¹ 

### ç»ƒä¹  1: è®©å›ç­”æ›´å…·ä½“

**ä»»åŠ¡**: ä¿®æ”¹ä¸‹é¢çš„ promptï¼Œè®© AI çš„å›ç­”æ›´å…·ä½“ï¼Œæ¯”å¦‚åªä»‹ç»çŒ«çš„ä¹ æ€§ã€‚

<PromptEditor
  exerciseId="lab1-ex1"
  mode="editable"
  initialValue="å‘Šè¯‰æˆ‘å…³äºçŒ«çš„äº‹æƒ…"
/>

<LLMOutputDisplay mode="live" />

**ç›®æ ‡**: è¾“å‡ºåº”è¯¥ä¸“æ³¨äºçŒ«çš„ä¹ æ€§ï¼Œè€Œä¸æ˜¯æ³›æ³›è€Œè°ˆã€‚

**æç¤º**: è¯•ç€åœ¨ prompt ä¸­æ˜ç¡®è¯´æ˜ä½ æƒ³äº†è§£"çŒ«çš„ä¹ æ€§"ã€‚

## ğŸ“ æ€»ç»“
- Prompt è¶Šå…·ä½“ï¼ŒAI çš„å›ç­”è¶Šå‡†ç¡®
- æ˜ç¡®è¯´æ˜ä½ æƒ³è¦ä»€ä¹ˆå†…å®¹
- ä¸‹ä¸€æ­¥ï¼šå­¦ä¹ å¦‚ä½•ç»™æ¸…æ™°çš„æŒ‡ä»¤
```

### 5.5 Server Action: runPrompt()

```typescript
// lib/actions/prompt-lab.ts
export async function runPrompt(request: {
  prompt: string
  labNumber: number
  exerciseId: string
}): Promise<RunPromptResult> {
  const user = await getCurrentUser()
  if (!user) throw new Error('Not authenticated')

  // 1. Validate input
  if (!request.prompt || request.prompt.length < 10) {
    return { success: false, error: 'Prompt å¤ªçŸ­,è‡³å°‘ 10 ä¸ªå­—ç¬¦' }
  }

  // 2. Rate limit check
  const allowed = await checkRateLimit(user.id, 'prompt_lab', 30, 60)
  if (!allowed) {
    return { success: false, error: 'æ“ä½œå¤ªé¢‘ç¹,è¯·ç¨åå†è¯•' }
  }

  // 3. Call GPT-4o
  const startTime = Date.now()
  let llmResponse: string

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        { role: 'user', content: request.prompt }
      ],
      max_tokens: 500,
      temperature: 0.7
    })

    llmResponse = response.choices[0].message.content || ''
  } catch (error) {
    console.error('[runPrompt] AI API error:', error)
    return { success: false, error: 'AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨' }
  }

  const latencyMs = Date.now() - startTime

  // 4. Check success criteria
  const successCheck = await checkExerciseSuccess(
    request.exerciseId,
    llmResponse
  )

  // 5. Persist submission
  await supabase.from('prompt_lab_progress').insert({
    user_id: user.id,
    lab_number: request.labNumber,
    exercise_id: request.exerciseId,
    prompt_submitted: request.prompt,
    llm_response: llmResponse,
    success: successCheck.success,
    attempts: 1, // TODO: increment existing attempts
    completed_at: successCheck.success ? new Date().toISOString() : null
  })

  // 6. Log usage
  await supabase.from('ai_usage_log').insert({
    user_id: user.id,
    action: 'prompt_lab'
  })

  return {
    success: true,
    output: llmResponse,
    passed: successCheck.success,
    feedback: successCheck.feedback,
    latencyMs
  }
}
```

### 5.6 Success Criteria Checking

```typescript
// lib/prompt-lab/success-checker.ts
interface SuccessCriteria {
  exerciseId: string
  rules: {
    type: 'containsKeywords' | 'minLength' | 'maxLength' | 'format' | 'sentiment'
    value: any
  }[]
  passingScore: number // éœ€è¦æ»¡è¶³å‡ æ¡è§„åˆ™
}

const exerciseCriteria: Record<string, SuccessCriteria> = {
  'lab1-ex1': {
    exerciseId: 'lab1-ex1',
    rules: [
      { type: 'containsKeywords', value: ['ä¹ æ€§', 'è¡Œä¸º', 'ç‰¹ç‚¹'] },
      { type: 'minLength', value: 50 }
    ],
    passingScore: 2
  },
  // ... more exercises
}

export async function checkExerciseSuccess(
  exerciseId: string,
  llmOutput: string
): Promise<{ success: boolean, feedback: string }> {
  const criteria = exerciseCriteria[exerciseId]
  if (!criteria) {
    // No criteria defined = always pass
    return { success: true, feedback: '' }
  }

  let passedRules = 0

  for (const rule of criteria.rules) {
    switch (rule.type) {
      case 'containsKeywords':
        const keywords = rule.value as string[]
        if (keywords.some(kw => llmOutput.includes(kw))) {
          passedRules++
        }
        break

      case 'minLength':
        if (llmOutput.length >= rule.value) {
          passedRules++
        }
        break

      case 'maxLength':
        if (llmOutput.length <= rule.value) {
          passedRules++
        }
        break

      // ... more rule types
    }
  }

  const success = passedRules >= criteria.passingScore

  let feedback = ''
  if (!success) {
    feedback = 'è¾“å‡ºè¿˜ä¸å¤ªç¬¦åˆè¦æ±‚ã€‚æç¤º: è¯•ç€è®© AI æ›´èšç„¦åœ¨å…·ä½“æ–¹é¢ã€‚'
  }

  return { success, feedback }
}
```

### 5.7 Coach Integration (å¤ç”¨ askCoach)

**æ›´æ–° Coach ä¸Šä¸‹æ–‡:**

```typescript
// lib/coach.ts
function getCoachSystemPrompt(context: string): string {
  if (context === 'PromptLab') {
    return `ä½ æ˜¯ä¸€ä¸ª Prompt Engineering æ•™å­¦åŠ©æ‰‹ï¼Œå¸®åŠ©åˆä¸­ç”Ÿå­¦ä¹ å¦‚ä½•ä¸ LLM å¯¹è¯ã€‚

èŒè´£:
- ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Š prompt æ¦‚å¿µ
- ç»™å‡ºå…·ä½“çš„æ”¹è¿›å»ºè®®ï¼ˆä¸æ˜¯æ³›æ³›è€Œè°ˆï¼‰
- é¼“åŠ±å­¦ç”Ÿå®éªŒä¸åŒçš„è¡¨è¾¾æ–¹å¼
- å½“å­¦ç”Ÿå¡ä½æ—¶ç»™äºˆæ°å½“æç¤º

é£æ ¼:
- å‹å¥½ã€è€å¿ƒ
- ä¸ä½¿ç”¨ä¸“ä¸šæœ¯è¯­
- å¤šç”¨æ¯”å–»å’Œä¾‹å­
- æ¯æ¬¡å›ç­”æ§åˆ¶åœ¨ 2-3 å¥è¯`
  }

  // ... other contexts
}
```

## 6. Authentication & Authorization

**å®Œå…¨å¤ç”¨ç°æœ‰å®ç°** - æ— å˜åŒ–

```typescript
// lib/supabase-client.ts - å¤ç”¨
// lib/supabase-server.ts - å¤ç”¨
// middleware.ts - å¤ç”¨ (ä¿æŠ¤ /dashboard/*)
```

**Rate Limiting** - æ›´æ–°é™åˆ¶:

- Prompt Lab: 30 æ¬¡æ‰§è¡Œ/å°æ—¶ (ä¹‹å‰æ˜¯ 10 æ¬¡ AI Agent)
- AI Coach: 20 questions/å°æ—¶ (ä¿æŒ)

## 7. Data Architecture

### 7.1 New Tables

```sql
-- Prompt Lab è¿›åº¦è¿½è¸ª
CREATE TABLE prompt_lab_progress (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
  lab_number SMALLINT NOT NULL CHECK (lab_number BETWEEN 1 AND 5),
  exercise_id TEXT NOT NULL, -- e.g., "lab1-ex1"

  -- Submission data
  prompt_submitted TEXT NOT NULL,
  llm_response TEXT NOT NULL,

  -- Success tracking
  success BOOLEAN DEFAULT false,
  attempts INT DEFAULT 1,

  -- Timestamps
  completed_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ NOT NULL DEFAULT now(),

  UNIQUE(user_id, lab_number, exercise_id)
);

CREATE INDEX idx_prompt_lab_user ON prompt_lab_progress(user_id, lab_number);
CREATE INDEX idx_prompt_lab_success ON prompt_lab_progress(user_id, success, created_at DESC);
```

### 7.2 Retained Tables (å¤ç”¨)

- `coach_transcripts` - å¤ç”¨ï¼ˆCoach å¯¹è¯è®°å½•ï¼‰
- `module_progress` - å¤ç”¨ï¼ˆæ¨¡å—çº§è¿›åº¦ï¼‰
- `ai_usage_log` - å¤ç”¨ï¼ˆRate limitingï¼‰

### 7.3 Removed Tables (ä¸å†éœ€è¦)

- âŒ `webcontainer_projects` - åˆ é™¤ï¼ˆä¸å†ä½¿ç”¨ WebContainerï¼‰
- âŒ `sandpack_submissions` - åˆ é™¤ï¼ˆä¸å†ä½¿ç”¨ Sandpackï¼‰

### 7.4 RLS Policies

```sql
ALTER TABLE prompt_lab_progress ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own progress"
  ON prompt_lab_progress FOR SELECT
  USING (auth.uid() = user_id);

CREATE POLICY "Users can insert own progress"
  ON prompt_lab_progress FOR INSERT
  WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update own progress"
  ON prompt_lab_progress FOR UPDATE
  USING (auth.uid() = user_id);
```

## 8. Performance Targets

| Metric | Target | Measured By |
|--------|--------|-------------|
| **Landing Page Load** | <1.5s | Vercel Analytics |
| **Lab Article Load** | <1s | Core Web Vitals (LCP) |
| **Prompt Submit â†’ Response** | <3s | Server action latency |
| **MDX Rendering** | <500ms | Client-side timing |
| **Success Check** | <100ms | Rule-based (instant) |
| **Coach Response** | <3s | `coach_transcripts.latency_ms` |

**Optimization Strategies:**

- **MDX**: Precompile at build time (SSG)
- **Components**: Code-split PromptEditor/LLMOutput
- **AI API**: Use streaming for long responses (optional)
- **Caching**: Cache common exercise prompts (Redis, åæœŸ)

## 9. Security

### 9.1 Attack Surface

**Threats:**

- âŒ Prompt Injection - Sanitize user prompts before AI calls
- âŒ XSS in LLM output - Escape HTML in response display
- âŒ API key leakage - Server-only environment variables
- âŒ Rate limit bypass - Supabase-backed rate limiting
- âŒ Content moderation - Use OpenAI's safety filters

### 9.2 Input Validation

```typescript
import { z } from 'zod'

const PromptLabSchema = z.object({
  prompt: z.string().min(10).max(1000),
  labNumber: z.number().int().min(1).max(5),
  exerciseId: z.string().regex(/^lab\d+-ex\d+$/)
})
```

### 9.3 Content Safety

```typescript
// Sanitize LLM output before displaying
function sanitizeLLMOutput(text: string): string {
  // Remove potential XSS vectors
  return text
    .replace(/<script>/gi, '&lt;script&gt;')
    .replace(/<iframe>/gi, '&lt;iframe&gt;')
}
```

## 10. Cost Estimates (MVP)

| Service | Usage | Cost |
|---------|-------|------|
| **Vercel** | Hobby tier, 100 GB bandwidth | $0 |
| **Supabase** | Free tier, <500MB data | $0 |
| **OpenAI GPT-4o** | 1000 students Ã— $0.14/student | $140/month |
| **Domain** | .com registration | $12/year |
| **Total** | First 1000 students | **~$140-150/month** |

**Scaling (10,000 students):**

- Vercel Pro: $20/month
- Supabase Pro: $25/month
- OpenAI API: $1,400/month
- **Total: ~$1,450/month**

## 11. Observability

### 11.1 Key Metrics

**Lab Completion Rate:**

```sql
SELECT
  lab_number,
  COUNT(DISTINCT user_id) AS total_students,
  COUNT(DISTINCT user_id) FILTER (WHERE success = true) AS completed,
  COUNT(DISTINCT user_id) FILTER (WHERE success = true)::FLOAT / COUNT(DISTINCT user_id) AS completion_rate
FROM prompt_lab_progress
WHERE created_at > now() - interval '7 days'
GROUP BY lab_number
ORDER BY lab_number;
```

**Average Attempts per Exercise:**

```sql
SELECT
  exercise_id,
  AVG(attempts) AS avg_attempts,
  MAX(attempts) AS max_attempts
FROM prompt_lab_progress
WHERE created_at > now() - interval '7 days'
GROUP BY exercise_id
ORDER BY avg_attempts DESC;
```

## 12. Future Enhancements (Post-MVP)

### Phase 2 (3-6 months)

- [ ] LLM-based success checking (æ›´çµæ´»çš„åˆ¤æ–­)
- [ ] Prompt ç‰ˆæœ¬å†å² (æŸ¥çœ‹å’Œæ¢å¤ä¹‹å‰çš„å°è¯•)
- [ ] å­¦ç”Ÿé—´åˆ†äº«ä¼˜ç§€ prompt ç¤ºä¾‹
- [ ] "è§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ª prompt æœ‰æ•ˆ" æŒ‰é’®

### Phase 3 (6-12 months)

- [ ] æ•™å¸ˆ Dashboard (æŸ¥çœ‹å…¨ç­è¿›åº¦)
- [ ] è‡ªå®šä¹‰ç»ƒä¹ é¢˜åˆ›å»ºå™¨
- [ ] å¤šè¯­è¨€æ”¯æŒ (è‹±æ–‡ç‰ˆ)
- [ ] ç§»åŠ¨ç«¯ App

## 13. Migration from Old System

**å…³é”®å˜åŒ–:**

| æ—§ç³»ç»Ÿ | æ–°ç³»ç»Ÿ | è¿ç§»ç­–ç•¥ |
|-------|-------|---------|
| WebContainer workspace | MDX article + editors | å®Œå…¨æ›¿æ¢ UI |
| `webcontainer_projects` table | `prompt_lab_progress` table | æ–°è¡¨,æ—§è¡¨å¯ä¿ç•™å¤‡ä»½ |
| AI Agent (function calling) | Simple LLM call | ç®€åŒ– AI é›†æˆ |
| Code generation focus | Prompt engineering focus | å†…å®¹é‡å†™ |
| Sandpack/Monaco editor | Simple textarea | ç§»é™¤é‡å‹ä¾èµ– |

**å¤ç”¨çš„éƒ¨åˆ†:**

- âœ… Authentication (Supabase Auth)
- âœ… Dashboard layout & navigation
- âœ… Coach interaction pattern (`askCoach()`)
- âœ… Progress tracking system
- âœ… Rate limiting infrastructure

## 14. Related Documentation

- [MDX Content Architecture](./mdx-content-architecture.md) - MDX é›†æˆè¯¦è§£
- [Prompt Lab Components](./prompt-lab-components.md) - ç»„ä»¶åº“æ–‡æ¡£
- [Data Model & Services](./data-model-and-services.md) - æ•°æ®åº“ schema
- [Tech Stack](./tech-stack.md) - æŠ€æœ¯æ ˆè¯¦è§£
- [Source Tree](./source-tree.md) - é¡¹ç›®æ–‡ä»¶ç»“æ„
- [Coding Standards](./coding-standards.md) - ä»£ç è§„èŒƒ

---

**Last Updated**: 2025-10-16
**Status**: Active Development (Migration from VibeCoding Lab to LLM Learning Lab)
**Next Review**: After refactor Phase 1 completion

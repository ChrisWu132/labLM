# LLM Learning Lab PRD (AI Literacy Education Platform)

## 1. Purpose & Vision

**Transform the existing platform into an LLM learning laboratory that combines theoretical understanding with hands-on practice, helping students understand LLM principles and master practical skills.**

Students first learn what LLMs are and how they work, then practice prompt techniques through embedded editors, seeing LLM outputs change in real-time, thereby building correct AI understanding and critical thinking.

**Vision**: "Through theory + practice, enable learners to understand AI principles, master practical skills, and become responsible AI users"

---

## 2. Target Learners

### Primary: Middle School Students (Ages 12-15)
- **Background**: Beginners curious about AI but with no prior knowledge
- **Goal**: Understand what LLMs are, how they work, what they can and cannot do
- **Pain**: "What is ChatGPT? Is it really thinking? Can I trust it?"
- **Success**:
  - âœ… Understand LLM fundamentals (training, generation, limitations)
  - âœ… Use LLMs effectively (clear communication, role-setting, guided reasoning)
  - âœ… Develop critical thinking (knowing when to trust, when to question)
  - âœ… Use AI responsibly (academic integrity, privacy protection)

### Secondary: Teen Programming Enthusiasts (Ages 15-18)
- **Background**: Some programming experience, wanting to dive deeper into AI
- **Goal**: Understand AI principles and apply them to real projects
- **Success**:
  - âœ… Master AI literacy fundamentals
  - âœ… Design complex prompts and workflows
  - âœ… Build foundation for further AI/ML learning

---

## 3. Core Product Changes (Platform Transformation)

### Unchanged âœ…
- **Overall page layout**: Dashboard, sidebar navigation
- **Lab list UI**: Left sidebar lab cards, completion tracking
- **Progress system**: Supabase-based progress tracking
- **User authentication**: Supabase auth
- **AI infrastructure**: askCoach() server action (reusable)
- **UI component library**: shadcn/ui, Tailwind CSS

### Core Changes ğŸ”„

| Previous Feature | New Feature | Reason |
|-----------------|-------------|---------|
| **Sandpack code editor** | **Article-based lessons + Embedded Prompt Editor** | No coding needed, focus on AI understanding and usage |
| **WebContainer Node.js environment** | **LLM API response display** | Direct LLM output display, no runtime needed |
| **File tree + terminal** | **Article content + Interactive experiments** | Simplified UI for theory learning + practice |
| **Observe AI coding** | **Understand AI principles + Practice prompt techniques** | Shift from coding to AI literacy education |

---

## 4. Product Journey Snapshot

| Lab | Duration | Topic | Theory | Practice | Learning Outcomes |
|-----|----------|-------|--------|----------|-------------------|
| **Lab 1** | 20 min | Meet Your AI Friend | What LLMs are, how they work | First conversation, refining questions | Understand LLMs + Ask questions |
| **Lab 2** | 25 min | How AI Gets Smart | Training process, knowledge sources | Clear communication practice | Understand training + Write specific prompts |
| **Lab 3** | 25 min | AI's "Thinking" Process | Generation mechanism, context role | Role-playing practice | Understand generation + Set roles |
| **Lab 4** | 30 min | AI's Capabilities & Limits | Superpowers vs weaknesses, hallucinations | Guide deep reasoning | Critical thinking + Advanced techniques |
| **Lab 5** | 30 min | Responsible AI Use | Ethics, academic integrity | Comprehensive scenarios | Ethical awareness + Integrated application |
| **Lab 6** | 60 min | AI Workflow Builder â­ | Problem decomposition, systems thinking | Observeâ†’Modifyâ†’Create workflows | Computational thinking + Workflow design |

**Total Duration**: ~3.2 hours for complete course

**Course Structure**: 40% theory + 60% practice - each lab follows "understand principles first, then practice"

**Note**: Lab 6 is an advanced "capstone project" integrating all knowledge and skills from Labs 1-5

---

## 5. Lab å†…å®¹ç»“æ„è®¾è®¡

### æ¯ä¸ª Lab çš„ç»Ÿä¸€ç»“æ„

```markdown
# Lab X: [ä¸»é¢˜åç§°]

## ğŸ“– å­¦ä¹ ç›®æ ‡
- ç›®æ ‡1
- ç›®æ ‡2
- ç›®æ ‡3

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

[æ–‡ç« å¼è®²è§£ï¼ŒåŒ…å«ï¼š]
- æ¦‚å¿µè§£é‡Š
- ä¸ºä»€ä¹ˆé‡è¦
- å®é™…åº”ç”¨åœºæ™¯

## ğŸ’¡ ç¤ºä¾‹å±•ç¤º

<PromptEditor readonly>
  ç¤ºä¾‹promptå†…å®¹
</PromptEditor>

<LLMOutput>
  å¯¹åº”çš„LLMè¾“å‡º
</LLMOutput>

## âœï¸ åŠ¨æ‰‹ç»ƒä¹ 

[2-3ä¸ªé€’è¿›å¼ç»ƒä¹ ]

### ç»ƒä¹  1: [ç»ƒä¹ åç§°]
**ä»»åŠ¡**: ä¿®æ”¹promptè¾¾åˆ°ç‰¹å®šç›®æ ‡

<PromptEditor editable initialValue="...">
  å­¦ç”Ÿå¯ç¼–è¾‘çš„promptèµ·ç‚¹
</PromptEditor>

<LLMOutput live>
  å®æ—¶æ˜¾ç¤ºAPIè°ƒç”¨ç»“æœ
</LLMOutput>

**ç›®æ ‡**: [æ¸…æ™°æè¿°æœŸæœ›çš„è¾“å‡ºç‰¹å¾]
**æç¤º**: [å¦‚æœå¡ä½äº†çš„å¼•å¯¼æ€§æç¤º]

## ğŸ“ æŒ‘æˆ˜é¢˜

**åœºæ™¯**: [å®é™…åº”ç”¨åœºæ™¯]
**ä½ çš„ä»»åŠ¡**: [å¼€æ”¾å¼ä»»åŠ¡æè¿°]

<PromptEditor editable blank>
  ç©ºç™½ç¼–è¾‘å™¨è®©å­¦ç”Ÿä»é›¶å¼€å§‹
</PromptEditor>

**æˆåŠŸæ ‡å‡†**:
- [ ] è¾“å‡ºåŒ…å«X
- [ ] è¾“å‡ºè¯­æ°”æ˜¯Y
- [ ] è¾“å‡ºé•¿åº¦çº¦Z

## ğŸ“ æ€»ç»“

- å…³é”®è¦ç‚¹1
- å…³é”®è¦ç‚¹2
- ä¸‹ä¸€æ­¥å­¦ä»€ä¹ˆ
```

---

## 6. Core Features

### 6.1 åµŒå…¥å¼ Prompt ç¼–è¾‘å™¨ç»„ä»¶

**æŠ€æœ¯æ–¹æ¡ˆ**: ç®€å•çš„ textarea + è¯­æ³•é«˜äº®ï¼ˆå¯é€‰ï¼‰

```typescript
<PromptEditor
  mode="readonly" | "editable" | "blank"
  initialValue={string}
  placeholder={string}
  onSubmit={(prompt) => callLLM(prompt)}
  showCharCount={boolean}
  maxLength={number}
/>
```

**åŠŸèƒ½**:
- âœ… å¤šè¡Œæ–‡æœ¬è¾“å…¥
- âœ… å­—ç¬¦è®¡æ•°æç¤º
- âœ… "è¿è¡Œ"æŒ‰é’®è°ƒç”¨ LLM API
- âœ… åŠ è½½çŠ¶æ€æ˜¾ç¤º
- âœ… é”™è¯¯å¤„ç†ï¼ˆAPIå¤±è´¥ã€è¶…æ—¶ï¼‰

**ä¸éœ€è¦**:
- âŒ å¤æ‚çš„ä»£ç ç¼–è¾‘å™¨ï¼ˆMonacoï¼‰
- âŒ æ–‡ä»¶ç®¡ç†
- âŒ ç»ˆç«¯æ¨¡æ‹Ÿ

### 6.2 LLM è¾“å‡ºå±•ç¤ºç»„ä»¶

```typescript
<LLMOutput
  mode="static" | "live"
  content={string}
  loading={boolean}
  error={string | null}
  showTokenCount={boolean}
  highlightDifferences={boolean} // å¯¹æ¯”å‰åè¾“å‡ºå˜åŒ–
/>
```

**åŠŸèƒ½**:
- âœ… æ ¼å¼åŒ–æ˜¾ç¤º LLM å“åº”
- âœ… åŠ è½½åŠ¨ç”»ï¼ˆæ‰“å­—æœºæ•ˆæœå¯é€‰ï¼‰
- âœ… é”™è¯¯æ¶ˆæ¯å‹å¥½å±•ç¤º
- âœ… å¯é€‰ï¼šæ˜¾ç¤ºtokenä½¿ç”¨é‡ï¼ˆæ•™è‚²ç›®çš„ï¼‰
- âœ… å¯é€‰ï¼šé«˜äº®è¾“å‡ºä¸­çš„å…³é”®å˜åŒ–

### 6.3 æ–‡ç« å†…å®¹æ¸²æŸ“ï¼ˆMDX åµŒå…¥ç»„ä»¶ï¼‰

**æŠ€æœ¯æ–¹æ¡ˆ**: MDXï¼ˆMarkdown + JSXï¼‰- æ”¯æŒåœ¨æ–‡ç« ä¸­åµŒå…¥ React ç»„ä»¶

**å…³é”®å†³ç­–**: âœ… **ç»„ä»¶å¿…é¡»å¯åµŒå…¥æ–‡ç« å†…**ï¼ˆç”¨æˆ·éœ€æ±‚ï¼‰

```mdx
# Lab 1: ä»€ä¹ˆæ˜¯ Prompt

æ­£æ–‡å†…å®¹ä»‹ç»æ¦‚å¿µ...

## ğŸ’¡ è¯•ä¸€è¯•

ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‚ç‚¹å‡»"è¿è¡Œ"çœ‹çœ‹ AI çš„å›ç­”ï¼š

<PromptEditor
  initialValue="å‘Šè¯‰æˆ‘å…³äºçŒ«çš„äº‹æƒ…"
  exerciseId="lab1-ex1"
/>

<LLMOutput mode="live" />

ç»§ç»­æ­£æ–‡è®²è§£ä¸ºä»€ä¹ˆè¿™ä¸ª prompt æœ‰æ•ˆ...
```

**å®ç°æ–¹æ¡ˆ**:
1. ä½¿ç”¨ `@next/mdx` æˆ– `next-mdx-remote`
2. åœ¨ MDX ä¸­ç›´æ¥ä½¿ç”¨ PromptEditor/LLMOutput ç»„ä»¶
3. ç»„ä»¶é—´é€šè¿‡ React Context å…±äº«çŠ¶æ€ï¼ˆprompt â†’ outputï¼‰

**æ–‡ä»¶ç»„ç»‡**:
```
app/dashboard/vibecoding/labs/
â”œâ”€â”€ lab1.mdx              # Lab 1 æ–‡ç« +ç»„ä»¶
â”œâ”€â”€ lab2.mdx              # Lab 2 æ–‡ç« +ç»„ä»¶
â”œâ”€â”€ lab3.mdx
â”œâ”€â”€ lab4.mdx
â””â”€â”€ lab5.mdx
```

### 6.4 å®æ—¶ LLM API è°ƒç”¨

**å¤ç”¨ç°æœ‰åŸºç¡€è®¾æ–½**: `askCoach()` server action

**è°ƒæ•´æ–¹æ¡ˆ**:
```typescript
// æ–°å¢ä¸“é—¨çš„ prompt lab è°ƒç”¨
export async function runPromptLab(request: {
  prompt: string
  labNumber: number
  exerciseId: string
}) {
  // 1. éªŒè¯ç”¨æˆ·è®¤è¯
  // 2. è°ƒç”¨çœŸå® LLM API (OpenAI/Anthropic)
  // 3. è®°å½•åˆ° lab_submissions è¡¨
  // 4. è¿”å›è¾“å‡º + metadata
}
```

**ä¸ askCoach() çš„åŒºåˆ«**:
- `askCoach()`: è¾…å¯¼æ€§å¯¹è¯ï¼Œæœ‰ä¸Šä¸‹æ–‡è®°å¿†
- `runPromptLab()`: å•æ¬¡ prompt æ‰§è¡Œï¼Œç”¨äºç»ƒä¹ 

### 6.5 è‡ªåŠ¨æˆåŠŸæ£€æŸ¥æœºåˆ¶ï¼ˆå…³é”®åŠŸèƒ½ï¼‰

**ç”¨æˆ·éœ€æ±‚**: âœ… **ç»ƒä¹ é¢˜å¿…é¡»è‡ªåŠ¨æ£€æŸ¥æˆåŠŸ**

**å®ç°æ–¹æ¡ˆ**: ä¸¤ç§æ–¹æ¡ˆå¹¶è¡Œ

#### æ–¹æ¡ˆ A: è§„åˆ™æ£€æŸ¥ï¼ˆæ¨èï¼Œé›¶æˆæœ¬ï¼‰

æ¯ä¸ªç»ƒä¹ å®šä¹‰æˆåŠŸæ ‡å‡†è§„åˆ™ï¼š

```typescript
interface SuccessCriteria {
  exerciseId: string
  rules: {
    containsKeywords?: string[]      // å¿…é¡»åŒ…å«çš„å…³é”®è¯
    minLength?: number                // æœ€å°å­—ç¬¦æ•°
    maxLength?: number                // æœ€å¤§å­—ç¬¦æ•°
    format?: 'json' | 'markdown' | 'plain'  // è¾“å‡ºæ ¼å¼
    sentiment?: 'positive' | 'negative' | 'neutral'  // æƒ…æ„Ÿå€¾å‘
    customRegex?: string              // è‡ªå®šä¹‰æ­£åˆ™è¡¨è¾¾å¼
  }[]
  passingScore: number  // æ»¡è¶³å‡ æ¡è§„åˆ™ç®—é€šè¿‡
}
```

**ç¤ºä¾‹**:
```typescript
// Lab 1 ç»ƒä¹  2: è®© AI å†™æ•…äº‹ï¼ˆåŒ…å«ç‰¹å®šå…ƒç´ ï¼‰
{
  exerciseId: "lab1-ex2",
  rules: [
    { containsKeywords: ["çŒ«", "å†’é™©"] },  // å¿…é¡»åŒ…å«ä¸»é¢˜è¯
    { minLength: 100 },                    // è‡³å°‘100å­—
    { sentiment: "positive" }              // ç§¯æçš„è¯­æ°”
  ],
  passingScore: 3  // 3æ¡éƒ½æ»¡è¶³æ‰é€šè¿‡
}
```

#### æ–¹æ¡ˆ B: LLM åˆ¤æ–­ï¼ˆå¤‡é€‰ï¼Œæ›´çµæ´»ä½†æœ‰æˆæœ¬ï¼‰

ç”¨å¦ä¸€ä¸ª GPT-4o-mini è°ƒç”¨åˆ¤æ–­ï¼š

```typescript
async function checkWithLLM(
  exerciseGoal: string,
  llmOutput: string
): Promise<{ success: boolean, feedback: string }> {
  const systemPrompt = `
ä½ æ˜¯ä¸€ä¸ªæ•™å­¦åŠ©æ‰‹ï¼Œåˆ¤æ–­å­¦ç”Ÿçš„ prompt ç»ƒä¹ æ˜¯å¦æˆåŠŸã€‚

ç»ƒä¹ ç›®æ ‡ï¼š${exerciseGoal}
LLM è¾“å‡ºï¼š${llmOutput}

è¯·åˆ¤æ–­ï¼š
1. è¾“å‡ºæ˜¯å¦ç¬¦åˆç»ƒä¹ ç›®æ ‡ï¼Ÿ
2. ç»™å‡ºç®€çŸ­åé¦ˆï¼ˆ1-2å¥è¯ï¼‰

è¿”å› JSON:
{ "success": true/false, "feedback": "..." }
  `

  // è°ƒç”¨ GPT-4o-mini è·å–åˆ¤æ–­
  // æˆæœ¬ï¼š~$0.01/æ¬¡
}
```

**æ¨èç­–ç•¥**:
- Lab 1-3: ä½¿ç”¨è§„åˆ™æ£€æŸ¥ï¼ˆç®€å•æ˜ç¡®ï¼‰
- Lab 4-5: å¯é€‰ä½¿ç”¨ LLM åˆ¤æ–­ï¼ˆæ›´å¤æ‚çš„æ ‡å‡†ï¼‰

### 6.6 è¿›åº¦è¿½è¸ª

**å¤ç”¨ç°æœ‰è¡¨ç»“æ„** + æ–°å¢å­—æ®µ:

```sql
-- å¤ç”¨ module_progress è¡¨
-- æ–°å¢ prompt_lab_progress è¡¨
CREATE TABLE prompt_lab_progress (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id),
  lab_number INT,
  exercise_id TEXT, -- e.g., "lab1-ex1"
  prompt_submitted TEXT,
  llm_response TEXT,
  success BOOLEAN, -- æ˜¯å¦è¾¾åˆ°ç›®æ ‡
  attempts INT,
  completed_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ
);
```

**æ–°å¢ç´¢å¼•**:
```sql
CREATE INDEX idx_prompt_lab_user ON prompt_lab_progress(user_id, lab_number);
```

---

## 7. Technical Blueprint (æ”¹åŠ¨èŒƒå›´)

### 7.1 éœ€è¦æ–°å»ºçš„ç»„ä»¶

```
components/features/prompt-lab/
â”œâ”€â”€ PromptEditor.tsx          # æ ¸å¿ƒç¼–è¾‘å™¨ç»„ä»¶
â”œâ”€â”€ LLMOutputDisplay.tsx      # è¾“å‡ºå±•ç¤ºç»„ä»¶
â”œâ”€â”€ LabArticle.tsx            # æ–‡ç« å®¹å™¨ç»„ä»¶
â”œâ”€â”€ ExerciseCard.tsx          # ç»ƒä¹ é¢˜å¡ç‰‡
â””â”€â”€ SuccessCriteria.tsx       # æˆåŠŸæ ‡å‡†æ£€æŸ¥å™¨
```

### 7.2 éœ€è¦ä¿®æ”¹çš„ç»„ä»¶

```
app/dashboard/vibecoding/
â”œâ”€â”€ page.tsx                  # ä¿æŒlabåˆ—è¡¨UIï¼Œåªæ”¹æ•°æ®æº
â””â”€â”€ vibecoding-client.tsx     # ä¿æŒå¸ƒå±€ï¼Œæ”¹å†…éƒ¨æ¸²æŸ“é€»è¾‘

app/dashboard/vibecoding/[labId]/
â””â”€â”€ page.tsx                  # æ–°å¢åŠ¨æ€è·¯ç”±é¡µé¢
    â””â”€â”€ lab-content.mdx       # MDXæ ¼å¼çš„labå†…å®¹
```

### 7.3 éœ€è¦æ–°å»ºçš„ Server Actions

```typescript
// lib/actions/prompt-lab.ts

export async function runPrompt(request: RunPromptRequest) {
  // è°ƒç”¨ LLM API
  // è®°å½•æäº¤
  // è¿”å›ç»“æœ
}

export async function checkSuccess(request: CheckSuccessRequest) {
  // âœ… å¿…é¡»ï¼šè‡ªåŠ¨æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æˆåŠŸæ ‡å‡†ï¼ˆç”¨æˆ·éœ€æ±‚ï¼‰
  // æ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰ï¼šåŸºäºè§„åˆ™æ£€æŸ¥ï¼ˆå…³é”®è¯ã€é•¿åº¦ã€æ ¼å¼ï¼‰
  // æ–¹æ¡ˆ2ï¼ˆå¤‡é€‰ï¼‰ï¼šç”¨å¦ä¸€ä¸ªLLMè°ƒç”¨åˆ¤æ–­æ˜¯å¦ç¬¦åˆæ ‡å‡†
  // è¿”å›ï¼š{ success: boolean, feedback: string }
}

export async function getLabContent(labNumber: number) {
  // è¿”å›labçš„æ–‡ç« å†…å®¹å’Œç»ƒä¹ ç»“æ„
}
```

### 7.4 æ•°æ®åº“è¿ç§»

**æ–°å¢è¿ç§»æ–‡ä»¶**: `supabase/migrations/20251016_prompt_lab.sql`

```sql
-- åˆ›å»º prompt_lab_progress è¡¨
-- æ·»åŠ å¿…è¦çš„ç´¢å¼•
-- è®¾ç½® RLS ç­–ç•¥
```

---

## 8. Lab Course Outline (Theory + Practice Integration)

### Lab 1: Meet Your AI Friend â€” What are LLMs + First Conversation (20 min)

**Part A: Understanding LLMs** (10 min)
- What is AI, what is an LLM
- LLM vs Search Engine vs Calculator
- How LLMs work (predicting the next word)
- AI is not a person, it's an intelligent tool
- Interactive experiments:
  - Ask simple questions, observe AI responses
  - Ask the same question 3 times, notice slight variations (understanding randomness)

**Part B: First Conversation** (10 min)
- ğŸ’¡ Concept: A prompt is an instruction to AI
- âœï¸ Exercise 1: Improve your question (vague â†’ clear)
- âœï¸ Exercise 2: Have AI write a story (adding details)
- ğŸ¯ Discovery: The clearer you communicate, the better AI responds

**Learning Outcomes**:
- âœ… Know what LLMs are and how they work
- âœ… Ask your first question
- âœ… Understand the importance of clear communication

---

### Lab 2: How AI Gets Smart + Learning Clear Communication (25 min)

**Part A: LLM's Learning Process** (12 min)
- How LLMs learn (training data, pattern recognition)
- What LLMs have "read" (internet text, books, code)
- Why some questions are answered well, others poorly
- Understanding knowledge cutoff dates
- Interactive experiments:
  - Ask about 2020 vs 2024 events â†’ Discover knowledge boundaries
  - Ask obscure vs common knowledge â†’ Understand data influence

**Part B: Clear Communication Techniques** (13 min)
- Why specificity matters (based on how LLMs work)
- Three elements: Details, Constraints, Context
- âœï¸ Exercise 1: Have AI write a story (vague â†’ specific)
  - Vague: "Write a story"
  - Specific: "Write a 200-word sci-fi story featuring a cat on an adventure"
- âœï¸ Exercise 2: Add format requirements
- ğŸ¯ Challenge: Get JSON format output

**Learning Outcomes**:
- âœ… Understand LLM learning sources and limitations
- âœ… Master clear communication methods
- âœ… Write effective detailed instructions

---

### Lab 3: AI's "Thinking" Process + Role-Playing Magic (25 min)

**Part A: How LLMs Generate Responses** (12 min)
- Token concept (how AI understands text)
- Word-by-word generation process
- Role of context (previous text determines what follows)
- Why responses vary slightly each time (probabilistic selection)
- Interactive experiments:
  - Ask same question multiple times â†’ Observe differences
  - Gradually add context â†’ See improved responses

**Part B: Role-Playing Techniques** (13 min)
- Why role-setting works (based on context understanding)
- System prompts / Role-setting function
- âœï¸ Exercise 1: Have AI play teacher explaining concepts
- âœï¸ Exercise 2: Have AI play poet writing poetry
- âœï¸ Exercise 3: Compare outputs from different roles
- ğŸ¯ Challenge: Design your custom AI assistant persona

**Learning Outcomes**:
- âœ… Understand LLM generation mechanisms
- âœ… Use role-setting to change output style
- âœ… Understand context's impact on responses

---

### Lab 4: AI's Capabilities & Limits + Guiding Deep Reasoning (30 min)

**Part A: LLM's Superpowers and Weaknesses** (15 min)
- âœ… Great at: Writing, summarizing, translating, explaining
- âš ï¸ Use caution: Math, facts, recent information
- âŒ Weaknesses: Complex reasoning, making up information
- Understanding "hallucinations" (AI inventing plausible-sounding but false information)
- Interactive experiments:
  - Math problem test â†’ Discover calculation errors
  - Fact-checking challenge â†’ Find outdated knowledge
  - Identify AI fabrications â†’ Learn to question

**Part B: Chain-of-Thought (Step-by-Step Reasoning)** (15 min)
- Why guide AI's "thinking" (compensating for reasoning weaknesses)
- How to make AI show reasoning steps
- âœï¸ Exercise 1: Have AI show problem-solving process
  - "Please explain your reasoning step by step"
- âœï¸ Exercise 2: Guide AI through complex problem analysis
- ğŸ¯ Challenge: Design multi-step guidance for real problems

**Learning Outcomes**:
- âœ… Clearly know what AI can and cannot do
- âœ… Develop critical thinking and fact-checking skills
- âœ… Master techniques for guiding AI's deep reasoning

---

### Lab 5: Responsible AI Use + Comprehensive Application (30 min)

**Part A: AI Ethics and Responsible Use** (12 min)
- Academic integrity: AI-assisted learning vs plagiarism
  - âœ… Good: Using AI to explain concepts, brainstorm ideas
  - âŒ Bad: Copying homework answers directly
- Privacy protection: What NOT to tell AI
  - âŒ Personal information, passwords, home addresses
- Case discussions and voting
- Create your personal "AI Usage Principles"

**Part B: Comprehensive Practice** (18 min)
Apply all techniques (clear communication, role-setting, step-by-step guidance)

- âœï¸ **Scenario 1: Learning Assistant**
  - Task: Have AI explain a difficult concept (e.g., "photosynthesis")
  - Requirement: Don't want direct answers, want to understand the reasoning
  - Techniques: Clear communication + Role-setting (teacher) + Guided reasoning

- âœï¸ **Scenario 2: Creative Writing Partner**
  - Task: Use AI to help write a short essay
  - Process: Brainstorm â†’ AI suggestions â†’ Your creation
  - Techniques: Role-setting (creative consultant) + Multi-turn dialogue

- âœï¸ **Scenario 3: Research Assistant**
  - Task: Research a topic (e.g., "dinosaur extinction")
  - Process: Information gathering â†’ Fact-checking â†’ Organize & summarize
  - Techniques: Clear communication + Critical thinking (verify information)

- ğŸ¯ **Open Challenge**: Solve your own real problem
  - Choose your own topic, apply all skills comprehensively

**Learning Outcomes**:
- âœ… Establish responsible AI usage mindset
- âœ… Flexibly apply all techniques in real scenarios
- âœ… Understand AI is a tool, you are the leader

---

### Lab 6: AI Workflow Builder (60 min) â­ Advanced Capstone Project

**Purpose**: Comprehensive application of all prompt engineering skills as a "capstone project"

**Learning Objectives**:
- Understand "complex tasks = combination of simple steps"
- Learn problem decomposition (computational thinking)
- Master prompt chaining
- Develop systems thinking

**Three Progressive Stages**:

**Stage 1: Observe Workflows (15 min)**
- See how preset "Story Creator" workflow runs
- Understand how data flows from step to step
- Observe variable substitution in prompts

**Stage 2: Modify Workflows (20 min)**
- Edit prompts for each step
- See how modifications affect final output
- Practice exercises:
  1. Make ideas more sci-fi
  2. Add story twists
  3. Change output tone

**Stage 3: Free Creation (25 min)**
- Build your own workflow from blank canvas
- Use block-style drag-and-drop (or click-to-add)
- Challenge tasks (choose 1 of 3):
  - Homework Helper (analyze problem â†’ hint reasoning â†’ verify method)
  - Translation Polisher (translate â†’ check â†’ improve)
  - Free Creation (design your own)

**Technical Implementation**:
- Visual workflows using React Flow
- Custom node types (Input, AI Step, Output)
- Lightweight execution engine
- Full detailed design: `docs/labs/lab6-workflow-builder.md`

**Educational Value**:
- â­â­â­â­â­ Cultivate "problem decomposition" computational thinking
- Understand AI agent and automation fundamentals
- Build foundation for future programming/AI engineering learning

**Cost Estimate**:
- ~37 LLM calls per student
- Cost: ~$0.17/student (Labs 1-5: $0.16)
- 6% increase, educational value far exceeds cost

---

## 9. Success Metrics

### Learning Outcome Metrics
- **80%+ completion rate**: Students complete Labs 1-5 (foundation course)
- **60%+ advanced completion**: Students complete Lab 6 (advanced project)
- **Average duration**: Each lab completed within target time
- **Exercise success rate**: 70%+ of exercises succeed on first or second attempt
- **Creation rate**: 50%+ of students create their own workflow in Lab 6

### Technical Metrics
- **LLM API response time**: <3 seconds
- **API success rate**: 95%+
- **Page load time**: <2 seconds

### Engagement Metrics
- **Retry attempts**: Average 1.5-2 attempts per exercise
- **Coaching requests**: 30%+ students use askCoach for help
- **Post-completion retention**: 50%+ students return within a week for review

---

## 10. Cost Estimates

### LLM API æˆæœ¬
**ç¡®å®šé€‰æ‹©**: âœ… **GPT-4o**ï¼ˆç”¨æˆ·å†³ç­–ï¼‰

**Lab 1-5 æˆæœ¬ï¼ˆåŸºç¡€è¯¾ç¨‹ï¼‰**:
- 5 labs Ã— å¹³å‡7æ¬¡ç»ƒä¹ /å®éªŒ = 35æ¬¡ API è°ƒç”¨/å­¦ç”Ÿ
- å¹³å‡æ¯æ¬¡è°ƒç”¨: 200 tokens input + 400 tokens output
- Input: 35 Ã— 200 = 7,000 tokens = $0.0175
- Output: 35 Ã— 400 = 14,000 tokens = $0.14
- **Lab 1-5 æˆæœ¬: ~$0.16/student**ï¼ˆæ¯”åŸè®¡åˆ’å¢åŠ $0.02ï¼Œå› ä¸ºå¢åŠ äº†ç†è®ºå®éªŒï¼‰

**Lab 6 æˆæœ¬ï¼ˆè¿›é˜¶å·¥ä½œæµï¼‰**:
- è§‚å¯Ÿ3æ¬¡ + ç¼–è¾‘8æ¬¡ + åˆ›å»º20æ¬¡ = 37æ¬¡ API è°ƒç”¨
- Input: 37 Ã— 200 = 7,400 tokens = $0.0185
- Output: 37 Ã— 400 = 14,800 tokens = $0.148
- **Lab 6 æˆæœ¬: ~$0.17/student**

**æ€»æˆæœ¬ï¼ˆ6ä¸ªlabsï¼‰**:
- **å®Œæ•´è¯¾ç¨‹: ~$0.33/student** (Lab 1-5: $0.16 + Lab 6: $0.17)

**è§„æ¨¡æˆæœ¬**:
- 100å­¦ç”Ÿ: ~$33/æœˆ
- 500å­¦ç”Ÿ: ~$165/æœˆ
- 1000å­¦ç”Ÿ: ~$330/æœˆ

**å®é™…æˆæœ¬é¢„ä¼°**:
- å¦‚ä½¿ç”¨ LLM åšæˆåŠŸæ£€æŸ¥: æ¯æ¬¡ç»ƒä¹ é¢å¤– +$0.01
- æ¨èï¼šä½¿ç”¨è§„åˆ™æ£€æŸ¥ï¼ˆé›¶æˆæœ¬ï¼‰
- é¢„è®¡80%å­¦ç”Ÿå®Œæˆ Lab 1-5ï¼Œ60%å­¦ç”Ÿå®Œæˆ Lab 6
- **å®é™…å¹³å‡æˆæœ¬: ~$0.26/student** ($0.16 Ã— 80% + $0.17 Ã— 60%)
- **100å­¦ç”Ÿå®é™…æˆæœ¬: ~$26/æœˆ**

---

## 11. Risks & Mitigations

### Risk 1: LLM è¾“å‡ºä¸å½“å†…å®¹
**Impact**: Highï¼ˆä¸é€‚åˆåˆä¸­ç”Ÿï¼‰
**Mitigation**:
- ä½¿ç”¨å¸¦ safety filter çš„ API
- Content moderation æ£€æŸ¥
- å®¶é•¿/æ•™å¸ˆç›‘ç£é€‰é¡¹

### Risk 2: å­¦ç”Ÿè§‰å¾—å¤ªç®€å•/å¤ªéš¾
**Impact**: Mediumï¼ˆæµå¤±ç‡ï¼‰
**Mitigation**:
- Betaæµ‹è¯•è°ƒæ•´éš¾åº¦
- æä¾›éš¾åº¦é€‰æ‹©ï¼ˆåŸºç¡€/è¿›é˜¶ï¼‰
- å®æ—¶åé¦ˆè°ƒæ•´

### Risk 3: API æˆæœ¬çªç„¶ä¸Šæ¶¨
**Impact**: Lowï¼ˆå¯æ§ï¼‰
**Mitigation**:
- Rate limitingï¼ˆæ¯å¤©æœ€å¤šXæ¬¡è°ƒç”¨ï¼‰
- ç¼“å­˜å¸¸è§ç»ƒä¹ ç­”æ¡ˆ
- é¢„ç•™æˆæœ¬buffer

---

## 12. Out of Scope (MVP)

**ä¸åš**:
- âŒ ä»£ç ç¼–å†™åŠŸèƒ½ï¼ˆçº¯ prompt å­¦ä¹ ï¼‰
- âŒ å¤šäººåä½œ
- âŒ æ•™å¸ˆdashboard
- âŒ è¯ä¹¦ç”Ÿæˆï¼ˆå¯åç»­æ·»åŠ ï¼‰
- âŒ ç§»åŠ¨ç«¯appï¼ˆweb firstï¼‰
- âŒ ä¸­æ–‡ä»¥å¤–çš„è¯­è¨€ç‰ˆæœ¬
- âŒ é«˜çº§promptæŠ€å·§ï¼ˆfunction calling, embeddingsç­‰ï¼‰

---

## 13. Implementation Phases

### Phase 1 (Week 1-2): æ ¸å¿ƒç»„ä»¶å¼€å‘
- âœ… PromptEditor ç»„ä»¶
- âœ… LLMOutputDisplay ç»„ä»¶
- âœ… runPrompt server action
- âœ… æ•°æ®åº“è¿ç§»
- **Milestone**: ä¸€ä¸ªå®Œæ•´çš„ç»ƒä¹ æµç¨‹å¯å·¥ä½œ

### Phase 2 (Week 2-3): Lab å†…å®¹åˆ›ä½œ
- âœ… Lab 1-3 å®Œæ•´å†…å®¹ï¼ˆæ–‡ç« +ç»ƒä¹ ï¼‰
- âœ… MDX é›†æˆå’Œæ¸²æŸ“
- âœ… è¿›åº¦è¿½è¸ªUI
- **Milestone**: å‰3ä¸ªlabså¯å®Œæ•´ä½“éªŒ

### Phase 3 (Week 3-4): Lab 4-5 + å®Œå–„
- âœ… Lab 4-5 å†…å®¹
- âœ… æˆåŠŸæ ‡å‡†è‡ªåŠ¨æ£€æŸ¥
- âœ… è¾…å¯¼åŠŸèƒ½é›†æˆ
- **Milestone**: å…¨éƒ¨5ä¸ªlabså®Œæˆ

### Phase 4 (Week 4-5): æµ‹è¯•å’Œä¼˜åŒ–
- âœ… Betaæµ‹è¯•ï¼ˆ10-20ä¸ªåˆä¸­ç”Ÿï¼‰
- âœ… æ ¹æ®åé¦ˆè°ƒæ•´å†…å®¹å’Œéš¾åº¦
- âœ… æ€§èƒ½ä¼˜åŒ–
- âœ… é”™è¯¯å¤„ç†å®Œå–„
- **Milestone**: å‡†å¤‡æ­£å¼å‘å¸ƒ

### Phase 5 (Week 5-6): å‘å¸ƒå‡†å¤‡
- âœ… Landing page æ›´æ–°
- âœ… ä½¿ç”¨æŒ‡å—/æ•™å¸ˆèµ„æº
- âœ… éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
- âœ… ç›‘æ§å’Œåˆ†æè®¾ç½®
- **Milestone**: æ­£å¼å‘å¸ƒ

---

## 14. Decisions & Open Questions

### âœ… å·²ç¡®è®¤çš„å†³ç­–

**äº§å“è®¾è®¡**:
- âœ… **Lab æ•°é‡**: 5ä¸ªåŸºç¡€ labs + 1ä¸ªè¿›é˜¶ labï¼ˆLab 6ï¼‰
- âœ… **éš¾åº¦è°ƒæ•´**: ä¸éœ€è¦éš¾åº¦åˆ†çº§ï¼Œç»Ÿä¸€ç‰ˆæœ¬
- âœ… **æˆåŠŸæ£€æŸ¥**: å¿…é¡»è‡ªåŠ¨æ£€æŸ¥ï¼Œä¸ç”¨å­¦ç”Ÿè‡ªè¯„
- âœ… **ç»„ä»¶åµŒå…¥**: PromptEditor å’Œ LLMOutput å¿…é¡»å¯åµŒå…¥æ–‡ç« å†…
- âœ… **Lab 6 å®šä½**: è¿›é˜¶"æ¯•ä¸šé¡¹ç›®"ï¼Œå¯è§†åŒ–å·¥ä½œæµæ­å»º

**æŠ€æœ¯é€‰å‹**:
- âœ… **LLM é€‰æ‹©**: GPT-4oï¼ˆç¡®è®¤ï¼‰
- âœ… **å†…å®¹ç»„ç»‡**: MDXï¼ˆæ”¯æŒç»„ä»¶åµŒå…¥ï¼‰
- âœ… **Lab 6 æŠ€æœ¯æ ˆ**: React Flow + è‡ªå®šä¹‰èŠ‚ç‚¹ + è½»é‡çº§æ‰§è¡Œå¼•æ“

### â“ å¾…ç¡®è®¤çš„é—®é¢˜

**äº§å“åŠŸèƒ½**:
- [ ] æ˜¯å¦å…è®¸å­¦ç”Ÿä¿å­˜å’Œåˆ†äº«ä¼˜ç§€promptï¼Ÿ
- [ ] æ˜¯å¦éœ€è¦"è§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ªpromptæœ‰æ•ˆ"çš„æŒ‰é’®ï¼Ÿ
- [ ] æ˜¯å¦éœ€è¦æŸ¥çœ‹å…¶ä»–å­¦ç”Ÿçš„ prompt ç¤ºä¾‹ï¼Ÿ

**è‡ªåŠ¨æ£€æŸ¥å®ç°**:
- [ ] è§„åˆ™æ£€æŸ¥ï¼ˆå…³é”®è¯+æ ¼å¼ï¼‰è¿˜æ˜¯ç”¨ LLM åˆ¤æ–­ï¼Ÿ
- [ ] æ£€æŸ¥å¤±è´¥æ—¶æä¾›ä»€ä¹ˆæ ·çš„æç¤ºï¼Ÿ
- [ ] å…è®¸å‡ æ¬¡é‡è¯•ï¼Ÿ

**å†…å®¹ç­–ç•¥**:
- [ ] æ˜¯å¦åŒ…å«"å¸¸è§é”™è¯¯"ç¤ºä¾‹å¯¹æ¯”ï¼Ÿ
- [ ] æ¯ä¸ªç»ƒä¹ æ˜¯å¦éœ€è¦"æç¤º"æŒ‰é’®ï¼Ÿ
- [ ] æ˜¯å¦å‚è€ƒ Anthropic è¯¾ç¨‹å†…å®¹ç»“æ„ï¼Ÿ

**æŠ€æœ¯ç»†èŠ‚**:
- [ ] æ˜¯å¦éœ€è¦ prompt ç‰ˆæœ¬å†å²è®°å½•ï¼Ÿ
- [ ] æ˜¯å¦éœ€è¦ç¦»çº¿æ¨¡å¼/ç¼“å­˜ï¼Ÿ

---

## 15. Competitive Positioning

| Feature | LLM Learning Lab | Anthropic Course | Other Coding Platforms |
|---------|-----------------|------------------|----------------------|
| **Target Audience** | Middle school students (12-15) | Adult developers | Teen programmers |
| **Teaching Focus** | AI Literacy (theory+practice) | Prompt engineering skills | Coding skills |
| **Duration** | 3.2 hours | 4-6 hours | Months |
| **Theory vs Practice** | 40% theory + 60% practice | 10% theory + 90% practice | 5% theory + 95% practice |
| **Critical Thinking** | âœ… Emphasized | âš ï¸ Limited | âŒ None |
| **Ethics Education** | âœ… Comprehensive | âš ï¸ Briefly mentioned | âŒ None |
| **Interactivity** | Real-time LLM calls | Static examples | Code exercises |
| **Barrier to Entry** | Zero prerequisites | Technical background needed | Programming required |
| **Language** | âœ… English | âœ… English | Mixed |
| **Price** | Free (MVP) | Free | $10-50/month |

**Unique Value**: "First AI literacy education platform for middle schoolers â€” teaching not just how to use AI, but what it is, why it works, and when to trust it"

---

## 16. Marketing Messages (For Parents/Schools)

### Core Value Propositions
ğŸ§  **AI Literacy Education**: Teaching not just how to use AI, but what it is, why it works, and when to question it
ğŸ¯ **Theory + Practice**: 40% understanding principles + 60% hands-on practice
âš¡ **Learn in 3 Hours**: Complete on a weekend, build proper AI understanding
ğŸ” **Critical Thinking**: Learn to question AI, verify information, avoid blind trust
âš–ï¸ **Responsible Use**: Comprehensive ethics education and academic integrity training
ğŸ§’ **Beginner-Friendly**: No coding required, suitable for all middle schoolers
ğŸŒ **Fully in English**: Clear, accessible educational content

### Parent FAQs
**Q: My child has no programming background. Can they learn this?**
A: Absolutely! The course starts with "What is AI?" â€” complete beginners welcome.

**Q: How is this different from typical AI tutorials?**
A: We don't just teach how to use AI. More importantly, we teach students to understand AI's principles, limitations, and proper usage. We cultivate AI literacy, not just operational skills.

**Q: What will my child gain from this?**
A: Students will:
- âœ… Understand how AI works and develop proper AI understanding
- âœ… Effectively use ChatGPT and similar tools to assist learning
- âœ… Develop critical thinking â€” knowing when to trust AI
- âœ… Use AI responsibly while maintaining academic integrity

**Q: Won't this make my child overly dependent on AI?**
A: Quite the opposite! The course specifically emphasizes AI's limitations and responsible use. We teach students to treat AI as an assistant tool, not an answer machine.

**Q: Is the content safe?**
A: All LLM outputs are filtered for safety. The course includes comprehensive privacy protection and safe usage education.

---

**Document Version**: 2.0 EN (AI Literacy Education Platform for Middle School Students)
**Created**: 2025-10-16
**Last Updated**: 2025-10-16
**Status**: âœ… Major Update: Transformed to AI Literacy Education (Theory + Practice) + Full English Localization

**Major Updates (v2.0 EN)**:
- âœ… **Teaching Focus Shift**: From pure skill training â†’ AI Literacy Education (40% theory + 60% practice)
- âœ… **Labs 1-5 Redesigned**: Each lab includes "Understanding Principles" + "Practice Techniques"
- âœ… **New Content**: Critical thinking, hallucination recognition, ethics education, responsible use
- âœ… **Lab 6 Retained**: Workflow builder as advanced "capstone project"
- âœ… **Full English Localization**: All content, UI, and documentation in English

**Confirmed Decisions**:
- âœ… 5 foundation labs (theory+practice) + 1 advanced lab (Lab 6 workflow)
- âœ… GPT-4o for LLM API
- âœ… MDX for articles + embedded components
- âœ… Rule-based checking (auto success validation)
- âœ… Unified difficulty (no leveling)
- âœ… Lab 6: React Flow visual workflow editor

**Key Documents**:
- ğŸ“„ Main PRD: This document
- ğŸ“„ Lab 6 Detailed Design: `docs/labs/lab6-workflow-builder.md`

**Next Steps**:
1. âœ… PRD v2.0 EN Complete (AI Literacy Education + English)
2. âœ… Lab 6 detailed design completed
3. ğŸ”„ Create or update Architecture document
4. ğŸ”„ Create Epic and detailed Stories (Labs 1-6)
5. ğŸ”„ Begin Phase 1 implementation (Week 1-2)
